{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ae83a0",
   "metadata": {},
   "source": [
    "## Fill in fields in PDF search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45caf9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library containign read and write functions to csv file\n",
    "import lib.handle_csv as csvh\n",
    "\n",
    "# managing files and file paths\n",
    "from pathlib import Path\n",
    "\n",
    "# library for handling url searchs\n",
    "import lib.handle_urls as urlh\n",
    "\n",
    "# add a progress bar\n",
    "from tqdm import tqdm_notebook\n",
    "    \n",
    "# library for accessing system functions\n",
    "import os\n",
    "\n",
    "# import custom functions (common to various notebooks)\n",
    "import processing_functions as pr_fns\n",
    "\n",
    "# date format\n",
    "from datetime import date\n",
    "\n",
    "# Connecting to the db\n",
    "import lib.handle_db as dbh\n",
    "\n",
    "# get the publications list from the app database\n",
    "ukchapp_db = \"./db_files/production.sqlite3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4728e226",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'doi', 'type', 'desc', 'data_url', 'action', 'link', 'issue', 'name', 'file', 'add', 'num', 'dataset_complete', 'dataset_description', 'dataset_doi', 'do_id', 'dataset_enddate', 'dataset_location', 'dataset_name', 'dataset_startdate', 'ds_type', 'repository', 'ID', 'in_db']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scman1\\AppData\\Local\\Temp\\ipykernel_17256\\3025757521.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for dr in tqdm_notebook(data_reference):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ab41b396034796921628a092a99a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get names and links for references in data mentions\n",
    "# data_reference, do_keys = csvh.get_csv_data('./data_search_pdf/new_references202111.csv')\n",
    "working_file = './data_search_pdf/pdf_mentionsapp_db202204_checked.csv'\n",
    "data_reference, do_keys = csvh.get_csv_data(working_file)\n",
    "print(do_keys)\n",
    "db_conn = dbh.DataBaseAdapter(ukchapp_db)\n",
    "\n",
    "for dr in tqdm_notebook(data_reference):\n",
    "    publication_title = db_conn.get_title(data_reference[dr]['doi'])\n",
    "    # db keys:\n",
    "    # 'dataset_complete', IGNORE\n",
    "    # 'dataset_description', try to add, if not use publication title\n",
    "    # get data from doi if available\n",
    "\n",
    "    if data_reference[dr]['dataset_description'] == \"\":\n",
    "        data_reference[dr]['dataset_description'] = data_reference[dr]['desc']\n",
    "        if data_reference[dr]['desc'] == \"\":\n",
    "            data_reference[dr]['doi'] = data_reference[dr]['doi'].lower().strip()\n",
    "            print (data_reference[dr]['link'], \"is missing description\" )\n",
    "            print(\"Description: Supplementary information for \", publication_title)\n",
    "            data_reference[dr]['dataset_description'] = \"Supplementary data for \" + publication_title[0]\n",
    "    # 'dataset_doi', if available\n",
    "    # 'do_id', need new field?\n",
    "    # 'dataset_enddate',IGNORE\n",
    "    #' dataset_location', URL (could be id)\n",
    "    if data_reference[dr]['dataset_location'] == \"\":\n",
    "        print(\"missing location for \",data_reference[dr]['link'])\n",
    "        data_reference[dr]['dataset_location'] = data_reference[dr]['link']\n",
    "    # 'dataset_name', try to add, if not use DO type and pub doi/id\n",
    "    if data_reference[dr]['dataset_name'] == \"\":\n",
    "        print(\"missing name for \",data_reference[dr]['link'])\n",
    "        data_reference[dr]['dataset_name'] = data_reference[dr]['type'] +\" (\"+ data_reference[dr]['type'] +\") for article\" \n",
    "    # 'dataset_startdate', try to add, use pub data if not available\n",
    "    if data_reference[dr]['dataset_startdate'] == \"\":\n",
    "        print(\"missing start data for \",data_reference[dr]['link'])\n",
    "        #try to get date from DOI\n",
    "        if data_reference[dr]['dataset_doi'] != \"\":\n",
    "            print(\"look up for doi data\")\n",
    "            ref_link = \"https://doi.org/\" + data_reference[dr]['dataset_doi']\n",
    "            data_object = urlh.getObjectMetadata(ref_link)\n",
    "            if 'metadata' in data_object.keys():\n",
    "                print(data_object['metadata'])\n",
    "                data_reference[dr]['dataset_description'] = data_object['metadata']['abstract']\n",
    "                if 'published' in data_object['metadata'].keys():\n",
    "                    print(data_object['metadata']['published'])\n",
    "        else:\n",
    "            print(\"get date from publication\")\n",
    "            db_data = db_conn.get_row(\"Articles\", data_reference[dr]['id'])\n",
    "            art_poy = db_conn.get_value(\"articles\", \"pub_ol_year\", \"id\", data_reference[dr]['id'])[0]\n",
    "            art_pom = db_conn.get_value(\"articles\", \"pub_ol_month\", \"id\", data_reference[dr]['id'])[0]\n",
    "            art_pod = db_conn.get_value(\"articles\", \"pub_ol_day\", \"id\", data_reference[dr]['id'])[0]\n",
    "            art_ppy = db_conn.get_value(\"articles\", \"pub_print_year\", \"id\", data_reference[dr]['id'])[0]\n",
    "            art_ppm = db_conn.get_value(\"articles\", \"pub_print_month\", \"id\", data_reference[dr]['id'])[0]\n",
    "            art_ppd = db_conn.get_value(\"articles\", \"pub_print_day\", \"id\", data_reference[dr]['id'])[0]\n",
    "            if art_poy != '' and art_pom != '' and art_pod != '' and art_poy != None and art_pom != None and art_pod != None:\n",
    "                print (\"use online date: \", art_poy, art_pom, art_pod, art_ppy, art_ppm, art_ppd)\n",
    "                data_reference[dr]['dataset_startdate'] = date(int(art_poy), int(art_pom), int(art_pod))\n",
    "            elif art_poy != '' and art_pom != '' and art_poy != None and art_pom != None:\n",
    "                print (\"use online date: \", art_poy, art_pom, art_pod, art_ppy, art_ppm, art_ppd)\n",
    "                data_reference[dr]['dataset_startdate'] = date(int(art_poy), int(art_pom), 1)\n",
    "            elif art_ppy != '' and art_ppm != '' and art_ppd != '' and art_ppy != None and art_ppm != None and art_ppd != None:\n",
    "                print (\"use print date: \",art_ppy, art_ppm, art_ppd)\n",
    "                data_reference[dr]['dataset_startdate'] = date(art_ppy, art_ppm, art_ppd)\n",
    "            elif art_ppy != '' and art_ppm != '' and art_ppy != None and art_ppm != None:\n",
    "                print (\"use print date: \",art_ppy, art_ppm, 1)\n",
    "                data_reference[dr]['dataset_startdate'] = date(art_ppy, art_ppm, 1)\n",
    "            elif art_poy != '' and art_poy != None:\n",
    "                print (\"use online date: \", art_poy, 1, 1)\n",
    "                data_reference[dr]['dataset_startdate'] = date(art_poy, 1, 1)\n",
    "    \n",
    "# write to csv file\n",
    "if len(data_reference) > 0:\n",
    "    csvh.write_csv_data(data_reference, working_file)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd3f19",
   "metadata": {},
   "source": [
    "## Fill in missing scholix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07fb80f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pub_id', 'pub_doi', 'source_title', 'source_published', 'target_id', 'target_title', 'target_published', 'rel_type', 'duplicate', 'in_db', 'dataset_complete', 'dataset_description', 'dataset_doi', 'do_id', 'dataset_enddate', 'dataset_location', 'dataset_name', 'dataset_startdate', 'ds_type', 'repository']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scman1\\AppData\\Local\\Temp\\ipykernel_17256\\2347414476.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for dr in tqdm_notebook(data_reference):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10061b03e1954e768692e83d09987fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get names and links for scholix data mentions\n",
    "working_file = './data_search_scholix/search_scholix_app_db202204_valid.csv'\n",
    "\n",
    "data_reference, do_keys = csvh.get_csv_data(working_file)\n",
    "print(do_keys)\n",
    "for dr in tqdm_notebook(data_reference):\n",
    "    if not 'dataset_complete' in do_keys:\n",
    "        do_id = data_reference[dr]['target_id']\n",
    "        data_reference[dr][\"dataset_complete\"]=\"\"\n",
    "        data_reference[dr][\"dataset_description\"]=\"\"\n",
    "        # fill in the DOI reference\n",
    "        if pr_fns.valid_doi(do_id):\n",
    "            print (do_id)\n",
    "            data_reference[dr]['dataset_doi'] = do_id\n",
    "        else:\n",
    "            data_reference[dr]['dataset_doi'] = \"\"    \n",
    "        data_reference[dr][\"do_id\"]=do_id\n",
    "        data_reference[dr][\"dataset_enddate\"]=\"\"\n",
    "        if pr_fns.valid_doi(do_id):\n",
    "            print (do_id)\n",
    "            data_reference[dr]['dataset_location'] = \"https://dx.doi.org/\"+do_id\n",
    "        else:\n",
    "            data_reference[dr]['dataset_location'] = do_id   \n",
    "        data_reference[dr][\"dataset_name\"]=data_reference[dr][\"target_title\"]\n",
    "        data_reference[dr][\"dataset_startdate\"]=data_reference[dr]['target_published']\n",
    "        data_reference[dr][\"ds_type\"]= \"\"\n",
    "        if \"CCDC\" in data_reference[dr][\"target_title\"]:\n",
    "            data_reference[dr][\"ds_type\"]= \"Crystallographic Information File [cif]\"\n",
    "        elif \"pdbe\" in  do_id :\n",
    "            data_reference[dr][\"ds_type\"]= \"Crystal structure [pdbe]\"\n",
    "        data_reference[dr][\"repository\"]=\"\"\n",
    "        if \"CCDC\" in data_reference[dr][\"target_title\"]:\n",
    "            data_reference[dr][\"repository\"]= \"https://www.ccdc.cam.ac.uk\"\n",
    "        elif \"pdbe\" in  do_id :\n",
    "            data_reference[dr][\"repository\"]= \"https://www.ebi.ac.uk\"\n",
    "        else:\n",
    "            data_reference[dr][\"repository\"] = do_id\n",
    "\n",
    "# write to csv file\n",
    "if len(data_reference) > 0:\n",
    "    csvh.write_csv_data(data_reference, working_file)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930c25a",
   "metadata": {},
   "source": [
    "## Join the references and add to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1319606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scman1\\AppData\\Local\\Temp\\ipykernel_17256\\1155673507.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for dr in tqdm_notebook(pdf_data_refs):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bd85e4f06441d7968e1006cf68e82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scman1\\AppData\\Local\\Temp\\ipykernel_17256\\1155673507.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for dr in tqdm_notebook(slx_data_refs):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c83d12f4194d93805624573cbb84c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get names and links for references in data mentions\n",
    "pdf_data = Path('./data_search_pdf/pdf_mentionsapp_db202204_checked.csv')\n",
    "pdf_data_refs, _ = csvh.get_csv_data(pdf_data)\n",
    "\n",
    "collected_refs = {}\n",
    "int_idx = 1\n",
    "for dr in tqdm_notebook(pdf_data_refs):\n",
    "    del pdf_data_refs[dr]['type']\n",
    "    del pdf_data_refs[dr]['desc']\n",
    "    del pdf_data_refs[dr]['data_url']\n",
    "    del pdf_data_refs[dr]['action']\n",
    "    del pdf_data_refs[dr]['link']\n",
    "    del pdf_data_refs[dr]['issue']\n",
    "    del pdf_data_refs[dr]['name']\n",
    "    del pdf_data_refs[dr]['file']\n",
    "    del pdf_data_refs[dr]['add']\n",
    "    del pdf_data_refs[dr]['num']\n",
    "    del pdf_data_refs[dr]['ID']\n",
    "    del pdf_data_refs[dr]['in_db']\n",
    "    collected_refs[int_idx] = pdf_data_refs[dr]\n",
    "    int_idx += 1\n",
    "    \n",
    "# get names and links for scholix data mentions\n",
    "slx_data = Path('./data_search_scholix/search_scholix_app_db202204_valid.csv')\n",
    "slx_data_refs, _ = csvh.get_csv_data(slx_data)\n",
    "for dr in tqdm_notebook(slx_data_refs):\n",
    "    collected_refs[int_idx] = {'id':slx_data_refs[dr]['pub_id'],'doi':slx_data_refs[dr]['pub_doi'],\n",
    "                               'dataset_complete':\"\", 'dataset_description':slx_data_refs[dr]['dataset_description'],\n",
    "                               'dataset_doi':slx_data_refs[dr]['dataset_doi'], 'do_id':slx_data_refs[dr]['do_id'], \n",
    "                               'dataset_enddate':'', 'dataset_location':slx_data_refs[dr]['dataset_location'],\n",
    "                               'dataset_name':slx_data_refs[dr]['dataset_name'], \n",
    "                               'dataset_startdate':slx_data_refs[dr]['dataset_startdate'], \n",
    "                               'ds_type':slx_data_refs[dr]['ds_type'], 'repository':slx_data_refs[dr]['repository']}\n",
    "    int_idx += 1\n",
    "\n",
    "out_file = Path('./data_load/data_load_202204.csv')\n",
    "\n",
    "# write to csv file\n",
    "if len(collected_refs) > 0:\n",
    "    csvh.write_csv_data(collected_refs, out_file)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db053604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scman1\\AppData\\Local\\Temp\\ipykernel_17256\\4139930805.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for dr in tqdm_notebook(data_reference):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e226cff8e5614670bab92fbc31bafb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1018\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n"
     ]
    }
   ],
   "source": [
    "# get names and links for references in data mentions\n",
    "in_file = Path('./data_load/data_load_202204.csv')\n",
    "\n",
    "data_reference, _ = csvh.get_csv_data(in_file)\n",
    "\n",
    "db_conn = dbh.DataBaseAdapter(ukchapp_db)\n",
    "\n",
    "db_table = \"datasets\"\n",
    "table_columns = [\"dataset_complete\", \"dataset_description\",\"dataset_doi\",\"dataset_enddate\", \"dataset_location\",\n",
    "                  \"dataset_name\",\"dataset_startdate\",\"created_at\",\"updated_at\", \"ds_type\", \"repository\"]\n",
    "for dr in tqdm_notebook(data_reference):\n",
    "    if data_reference[dr]['dataset_location']!= \"\":\n",
    "        table_values = [None, data_reference[dr]['dataset_description'], data_reference[dr]['dataset_doi'], None,\n",
    "                        data_reference[dr]['dataset_location'],data_reference[dr]['dataset_name'], \n",
    "                        data_reference[dr]['dataset_startdate'], \"2022-05-06 18:48:00\", \"2022-05-06 18:48:00\", \n",
    "                        data_reference[dr]['ds_type'], data_reference[dr]['repository']]\n",
    "        db_conn.put_values_table(db_table, table_columns, table_values)\n",
    "        #get the id of inserted record\n",
    "        new_do_id = db_conn.get_value( db_table, \"id\", \"dataset_location\", data_reference[dr]['dataset_location'])[0]\n",
    "        print(new_do_id)\n",
    "        linktable = \"article_datasets\"\n",
    "        linktable_columns = [\"doi\", \"article_id\", \"dataset_id\", \"created_at\", \"updated_at\"]\n",
    "        linktable_values = [data_reference[dr]['doi'], data_reference[dr]['id'], new_do_id, \"2022-05-06 18:48:00\",\n",
    "                            \"2022-05-06 18:48:00\"]\n",
    "        db_conn.put_values_table(linktable, linktable_columns, linktable_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeac99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
