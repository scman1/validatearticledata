{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2203ecf9",
   "metadata": {},
   "source": [
    "# Sinlge Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8876949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# single layer perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "# multilayer perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# handle  csv read and write\n",
    "import lib.handle_csv as csvh\n",
    "# library for connecting to the db\n",
    "# managing files and file paths\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd395e9f",
   "metadata": {},
   "source": [
    "### Get test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0f10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestData(pdf_data_search_dir, in_name):\n",
    "    data_mentions, dm_headers = csvh.get_csv_data(Path(pdf_data_search_dir, in_name+'.csv'))\n",
    "    corpus = []\n",
    "    targets = []\n",
    "    for a_line in data_mentions:\n",
    "        corpus.append(data_mentions[a_line]['desc'])\n",
    "        targets.append(int(data_mentions[a_line]['DataStatement']))\n",
    "    # Create the training and test sets\n",
    "    \n",
    "    # split the dataset\n",
    "    train_features, test_features, train_targets, test_targets = train_test_split(corpus,targets,test_size=0.2, random_state = 123)\n",
    "    # Turn the corpus into a tf-idf array\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, norm='l1')\n",
    "    train_features = vectorizer.fit_transform(train_features)\n",
    "    test_features = vectorizer.transform(test_features)\n",
    "    \n",
    "    return train_features, test_features, train_targets, test_targets, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f231f75",
   "metadata": {},
   "source": [
    "### Build the single layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b55f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPerceptron(train_features, train_targets):\n",
    "    classifier = Perceptron(random_state=457)\n",
    "    classifier.fit (train_features, train_targets)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20a2e8",
   "metadata": {},
   "source": [
    "### Train and test perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8905b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAndTrainSLP(train_features, train_targets):\n",
    "    slp_classifier = buildPerceptron(train_features, train_targets)\n",
    "\n",
    "    predictions = slp_classifier.predict(test_features)\n",
    "\n",
    "    score = np.round(metrics.accuracy_score(test_targets, predictions),2)\n",
    "\n",
    "    print(\"Mean accuracy of predictions: \"+ str(score))\n",
    "    #print(list(predictions))\n",
    "    #print(test_targets)\n",
    "    #print(list(predictions-test_targets))\n",
    "    return slp_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd34b5",
   "metadata": {},
   "source": [
    "### Use the generated model to predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7f765b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of predictions: 0.85\n"
     ]
    }
   ],
   "source": [
    "# get train and test data\n",
    "\n",
    "# working directory\n",
    "pdf_data_search_dir = \"./data_search_pdf_b\"\n",
    "\n",
    "# file containing train and test data\n",
    "train_test_file =  'test_train01_a'\n",
    "\n",
    "train_features, test_features, train_targets, test_targets, vectorizer = getTrainTestData(pdf_data_search_dir, train_test_file)\n",
    "\n",
    "\n",
    "# build and train model\n",
    "slp_classifier = buildAndTrainSLP(train_features, train_targets)\n",
    "# get evalutation data\n",
    "pdf_data_search_dir = \"./data_search_pdf_b\"\n",
    "\n",
    "start_from = 201\n",
    "stop_at = 250\n",
    "\n",
    "eval_file = \"pdf_mentions_\" + str(start_from).zfill(4) + \"_\" + str(stop_at).zfill(4)\n",
    "\n",
    "res_file = eval_file + \"_pre_res\"\n",
    "\n",
    "eval_mentions, eval_headers = csvh.get_csv_data(Path(pdf_data_search_dir, eval_file+'.csv'))\n",
    "\n",
    "eval_data = [eval_mentions[dic]['desc'] for dic in eval_mentions]\n",
    "\n",
    "eval_features = vectorizer.transform(eval_data)\n",
    "eval_prediction = slp_classifier.predict(eval_features)\n",
    "\n",
    "current_pub = 0\n",
    "for data, slc_pred in zip(eval_mentions, eval_prediction):        \n",
    "    eval_mentions[data]['predicted'] = slc_pred\n",
    "    eval_mentions[data]['true_val'] = 0 # placeholder for manual evaluation\n",
    "    # mark the first and last lines as new candidates regardles of their value\n",
    "    if eval_mentions[data]['id'] != current_pub:\n",
    "        if current_pub != 0 :\n",
    "            eval_mentions[data]['add'] = 1\n",
    "            eval_mentions[data-1]['add'] = 1\n",
    "        else:\n",
    "            eval_mentions[data]['add'] = 1\n",
    "        current_pub = eval_mentions[data]['id']\n",
    "        \n",
    "\n",
    "csvh.write_csv_data(eval_mentions, Path(pdf_data_search_dir,  res_file +'.csv'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a1853",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "The MLP uses the same training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "016ebf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMLPerceptron(train_features, test_features, train_targets, test_targets, num_neurons = 2):\n",
    "    # Build a MultiLayer perceptron and fit the data\n",
    "    # Activation function: ReLU\n",
    "    # Optimisation Function: Stochastic Gradient Descent (SGD)\n",
    "    # Learning Rate: Inverse Scaling\n",
    "    classifier = MLPClassifier(hidden_layer_sizes = num_neurons, max_iter=35, activation='relu', solver='sgd', verbose=10, random_state=762, learning_rate='invscaling')\n",
    "    classifier.fit(train_features,train_targets)\n",
    "    \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c711098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.94429406\n",
      "Iteration 2, loss = 0.94340443\n",
      "Iteration 3, loss = 0.94272826\n",
      "Iteration 4, loss = 0.94222274\n",
      "Iteration 5, loss = 0.94181200\n",
      "Iteration 6, loss = 0.94151745\n",
      "Iteration 7, loss = 0.94128288\n",
      "Iteration 8, loss = 0.94108928\n",
      "Iteration 9, loss = 0.94093606\n",
      "Iteration 10, loss = 0.94080481\n",
      "Iteration 11, loss = 0.94070191\n",
      "Iteration 12, loss = 0.94061382\n",
      "Iteration 13, loss = 0.94053808\n",
      "Iteration 14, loss = 0.94047089\n",
      "Iteration 15, loss = 0.94041199\n",
      "Iteration 16, loss = 0.94035830\n",
      "Iteration 17, loss = 0.94030878\n",
      "Iteration 18, loss = 0.94026430\n",
      "Iteration 19, loss = 0.94022032\n",
      "Iteration 20, loss = 0.94018055\n",
      "Iteration 21, loss = 0.94014116\n",
      "Iteration 22, loss = 0.94010466\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean accuracy of predictions: 0.48252\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1\n",
      " 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier =  buildMLPerceptron(train_features, test_features, train_targets, test_targets, 2)\n",
    "\n",
    "predictions = mlp_classifier.predict(test_features)\n",
    "    \n",
    "score = np.round(metrics.accuracy_score(test_targets, predictions),5)\n",
    "\n",
    "print(\"Mean accuracy of predictions: \"+ str(score))\n",
    "print(predictions)\n",
    "print(test_targets)\n",
    "print(predictions-test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fc9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312c88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
