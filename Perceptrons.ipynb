{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2203ecf9",
   "metadata": {},
   "source": [
    "# Sinlge Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8876949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# single layer perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "# multilayer perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# handle  csv read and write\n",
    "import lib.handle_csv as csvh\n",
    "# library for connecting to the db\n",
    "# managing files and file paths\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd395e9f",
   "metadata": {},
   "source": [
    "### Get test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0f10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestData(pdf_data_search_dir, in_name):\n",
    "    data_mentions, dm_headers = csvh.get_csv_data(Path(pdf_data_search_dir, in_name+'.csv'))\n",
    "    corpus = []\n",
    "    targets = []\n",
    "    for a_line in data_mentions:\n",
    "        corpus.append(data_mentions[a_line]['desc'])\n",
    "        targets.append(int(data_mentions[a_line]['DataStatement']))\n",
    "    # Create the training and test sets\n",
    "    \n",
    "    # split the dataset\n",
    "    train_features, test_features, train_targets, test_targets = train_test_split(corpus,targets,test_size=0.2, random_state = 123)\n",
    "    # Turn the corpus into a tf-idf array\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, norm='l1')\n",
    "    train_features = vectorizer.fit_transform(train_features)\n",
    "    test_features = vectorizer.transform(test_features)\n",
    "    \n",
    "    return train_features, test_features, train_targets, test_targets, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f231f75",
   "metadata": {},
   "source": [
    "### Build the single layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b55f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPerceptron(train_features, train_targets):\n",
    "    classifier = Perceptron(random_state=457)\n",
    "    classifier.fit (train_features, train_targets)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20a2e8",
   "metadata": {},
   "source": [
    "#### Train and test slp perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8905b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAndTrainSLP(train_features, train_targets):\n",
    "    slp_classifier = buildPerceptron(train_features, train_targets)\n",
    "\n",
    "    predictions = slp_classifier.predict(test_features)\n",
    "\n",
    "    score = np.round(metrics.accuracy_score(test_targets, predictions),2)\n",
    "\n",
    "    print(\"SLP Mean accuracy of predictions: \"+ str(score))\n",
    "    return slp_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a1853",
   "metadata": {},
   "source": [
    "### Build and test Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016ebf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMLPerceptron(train_features, test_features, train_targets, test_targets, num_neurons = 2):\n",
    "    # Build a MultiLayer perceptron and fit the data\n",
    "    # Activation function: ReLU\n",
    "    # Optimisation Function: Stochastic Gradient Descent (SGD)\n",
    "    # Learning Rate: Inverse Scaling\n",
    "    classifier = MLPClassifier(hidden_layer_sizes = num_neurons, max_iter=100, activation='relu', solver='sgd', verbose=10, random_state=762, learning_rate='invscaling')\n",
    "    classifier.fit(train_features,train_targets)\n",
    "    \n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    score = np.round(metrics.accuracy_score(test_targets, predictions),2)\n",
    "\n",
    "    print(\"MLP Mean accuracy of predictions: \"+ str(score))\n",
    "    \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553ad10",
   "metadata": {},
   "source": [
    "### Build classifier models using prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7d8fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLP Mean accuracy of predictions: 0.91\n",
      "Iteration 1, loss = 0.55428818\n",
      "Iteration 2, loss = 0.55421022\n",
      "Iteration 3, loss = 0.55418931\n",
      "Iteration 4, loss = 0.55418571\n",
      "Iteration 5, loss = 0.55418428\n",
      "Iteration 6, loss = 0.55418328\n",
      "Iteration 7, loss = 0.55418233\n",
      "Iteration 8, loss = 0.55418150\n",
      "Iteration 9, loss = 0.55418069\n",
      "Iteration 10, loss = 0.55418003\n",
      "Iteration 11, loss = 0.55417944\n",
      "Iteration 12, loss = 0.55417884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "MLP Mean accuracy of predictions: 0.79\n"
     ]
    }
   ],
   "source": [
    "# get train and test data\n",
    "\n",
    "# working directory\n",
    "pdf_data_search_dir = \"./data_search_pdf_b\"\n",
    "\n",
    "# file containing train and test data\n",
    "train_test_file =  'test_train01_r2_c'\n",
    "\n",
    "train_features, test_features, train_targets, test_targets, vectorizer = getTrainTestData(pdf_data_search_dir, train_test_file)\n",
    "\n",
    "\n",
    "# build and train models\n",
    "# single layer\n",
    "slp_classifier = buildAndTrainSLP(train_features, train_targets)\n",
    "# multilayer\n",
    "mlp_classifier =  buildMLPerceptron(train_features, test_features, train_targets, test_targets, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd34b5",
   "metadata": {},
   "source": [
    "### Use the generated models to predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f765b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get evalutation data\n",
    "pdf_data_search_dir = \"./data_search_pdf_b\"\n",
    "\n",
    "start_from = 901\n",
    "stop_at = 1000\n",
    "\n",
    "eval_file = \"pdf_mentions_\" + str(start_from).zfill(4) + \"_\" + str(stop_at).zfill(4)+\"_corr\"\n",
    "\n",
    "#eval_file = \"rev_positives\"\n",
    "\n",
    "res_file = eval_file + \"_pre_res_2\"\n",
    "\n",
    "\n",
    "\n",
    "eval_mentions, eval_headers = csvh.get_csv_data(Path(pdf_data_search_dir, eval_file+'.csv'))\n",
    "\n",
    "eval_data = [eval_mentions[dic]['desc'] for dic in eval_mentions]\n",
    "\n",
    "eval_features = vectorizer.transform(eval_data)\n",
    "eval_prediction_slp = slp_classifier.predict(eval_features)\n",
    "eval_prediction_mlp = mlp_classifier.predict(eval_features)\n",
    "\n",
    "current_pub = 0\n",
    "for data, slp_pred, mlp_pred in zip(eval_mentions, eval_prediction_slp, eval_prediction_mlp):        \n",
    "    eval_mentions[data]['slp_pred'] = slp_pred\n",
    "    eval_mentions[data]['mlp_pred'] = mlp_pred\n",
    "    eval_mentions[data]['true_val'] = 0 # placeholder for manual evaluation\n",
    "    # mark the first and last lines as new candidates regardles of their value\n",
    "    if eval_mentions[data]['id'] != current_pub:\n",
    "        if current_pub != 0 :\n",
    "            eval_mentions[data]['add'] = 1\n",
    "            eval_mentions[data-1]['add'] = 1\n",
    "        else:\n",
    "            eval_mentions[data]['add'] = 1\n",
    "        current_pub = eval_mentions[data]['id']\n",
    "        \n",
    "\n",
    "csvh.write_csv_data(eval_mentions, Path(pdf_data_search_dir,  res_file +'.csv'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55978160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
