{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2203ecf9",
   "metadata": {},
   "source": [
    "# Prepare corpus \n",
    "clean strings and add corrected to see if the predictions improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8876949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle  csv read and write\n",
    "import lib.handle_csv as csvh\n",
    "# library for connecting to the db\n",
    "# managing files and file paths\n",
    "from pathlib import Path\n",
    "\n",
    "import enchant\n",
    "#d = enchant.Dict(\"en\")\n",
    "\n",
    "#d.check(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a470aff",
   "metadata": {},
   "source": [
    "## Handle non dictionary instances\n",
    "if a word is not in the dictionary it can either:\n",
    "  - Merge of two or more words (space by PDF reader)\n",
    "  - A non-dictionary word (Proper name, abreviation)\n",
    "  - A nom-word (code word, Acronym Chemical formula, reference, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c20900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# split difficult word\n",
    "def split_difficult(a_word,uw):\n",
    "    # try to split with previously found words\n",
    "    collected = split_with_used(a_word,uw)\n",
    "    # split words manually\n",
    "    if len(collected) == 0:\n",
    "        collected = split_manually(a_word)\n",
    "    return collected\n",
    "\n",
    "# try to split with previously found words\n",
    "#   try to match existing words\n",
    "def split_with_used(str_this, used_words):\n",
    "    split_word = []\n",
    "    while str_this != \"\":\n",
    "        temp = \"\"\n",
    "        for auw in used_words:\n",
    "            if auw in str_this and str_this.index(auw) == 0:\n",
    "                if len(auw) > len(temp):\n",
    "                    temp = auw\n",
    "        if temp != \"\":\n",
    "            split_word.append(temp)\n",
    "            str_this=str_this.replace(temp, \"\")\n",
    "        else:\n",
    "            break\n",
    "    if str_this != \"\" and split_word != []:\n",
    "        split_word.append(str_this)\n",
    "    return split_word\n",
    "\n",
    "# split words manually\n",
    "def split_manually(a_word):\n",
    "    collected = []\n",
    "    while a_word!= \"\":\n",
    "        addthis, a_word = get_from_string(a_word)\n",
    "        collected.append(addthis)\n",
    "    return collected\n",
    "\n",
    "# get one word and remainder of string\n",
    "def get_from_string(string_value):\n",
    "    element_value = \"\"\n",
    "    print(\"************ get *************************\")\n",
    "    print(\"split and add this: \", string_value)\n",
    "    element_value = extract_custom(string_value)\n",
    "    string_value = string_value.replace(element_value,'')\n",
    "    string_value = remove_extra_commas(string_value)\n",
    "    return element_value, string_value\n",
    "\n",
    "# remove punctuation on the edges\n",
    "def remove_extra_commas(str_this):\n",
    "    str_this = str_this.replace(\", ,\", \"\")\n",
    "    str_this = str_this.replace(\"; ;\", \"\")\n",
    "    str_this = str_this.replace(\" ;\", \";\")\n",
    "    str_this = str_this.strip()\n",
    "    if len(str_this) == 0:\n",
    "        return \"\"\n",
    "    return remove_lt_punctuation(str_this)\n",
    "\n",
    "# remove leading and trailing punctuation from string\n",
    "def remove_lt_punctuation(str_this):\n",
    "    if str_this[0] in (\",\",\";\",\".\",\"(\",\"{\",\"[\",\")\",\"}\",\"]\") : str_this = str_this[1:] \n",
    "    if str_this[-1:] in (\",\",\";\",\".\",\"(\",\"{\",\"[\",\")\",\"}\",\"]\") : str_this = str_this[:-1] \n",
    "    return str_this.strip()\n",
    "\n",
    "# select portion of string to break\n",
    "def extract_custom(split_this):\n",
    "    print(split_this)\n",
    "    decimal_str = \"\"\n",
    "    for indx in range(0, len(split_this)):\n",
    "        val = \" \"\n",
    "        if (indx % 10 == 0): val = str(int(indx/10)) \n",
    "        decimal_str += val\n",
    "    print(decimal_str)\n",
    "    unit_str = \"\"\n",
    "    for indx in range(0, len(split_this)):\n",
    "        val = str(indx%10)\n",
    "        if (indx % 10 == 0): val = \"0\" \n",
    "        unit_str += val\n",
    "    print(unit_str)\n",
    "    print(\"start\")\n",
    "    str_start = int(input())\n",
    "    print(\"end\")\n",
    "    str_end = int(input())\n",
    "    clear_output()\n",
    "    return split_this[str_start:str_end+1]\n",
    "\n",
    "# if word is dictionary word do not check and larger than 3\n",
    "def need_to_check(a_word):\n",
    "    check_it = False\n",
    "    #if string is alphanumeric\n",
    "    only_alphanum = re.sub(r'[^a-zA-Z0-9]', '', a_word)\n",
    "    only_alpha = re.sub(r'[^a-zA-Z]', '', a_word)\n",
    "    only_num = re.sub(r'[^0-9]', '', a_word) \n",
    "    if len(only_alpha) >= 3 and len(only_alpha) > len(only_num):\n",
    "        check_it = True\n",
    "    return check_it\n",
    "\n",
    "# return only alphanumeric characters in word\n",
    "def get_alphanum(a_word):\n",
    "    ret_str = re.sub(r'\\W+', '', a_word)\n",
    "    return ret_str\n",
    "\n",
    "def add_word_to_list(words_list, a_word):\n",
    "    if not a_word in words_list:\n",
    "        words_list.append(a_word)\n",
    "    return words_list\n",
    "\n",
    "def check_non_dict(a_word, words_list):\n",
    "    return (a_word in words_list)\n",
    "\n",
    "def check_difficult(a_word, non_dict, used_words):\n",
    "    print(\"D WORD:\", a_word)\n",
    "    opt_user=\"\"\n",
    "    diff_string = []\n",
    "    if not need_to_check(a_word):\n",
    "        opt_user=\"c\"\n",
    "    # try to split with used \n",
    "    diff_string = split_with_used(a_word, used_words)\n",
    "    if diff_string !=[]:\n",
    "        opt_user=\"a\"\n",
    "    while not opt_user in ['a','b','c']:\n",
    "        print(\"options:\\n\\ta) split and add\\n\\tb) add to non dictionary\\n\\tc) ignore\")\n",
    "        opt_user = input()\n",
    "    if opt_user == 'a':\n",
    "        print(\"need to split this\")\n",
    "        diff_string = split_difficult(a_word, used_words)\n",
    "    elif opt_user == 'b':\n",
    "        print(\"add to non dictionary\")\n",
    "        a_word = re.sub(r'\\W+', '', a_word)\n",
    "        non_dict = add_word_to_list(non_dict, a_word)\n",
    "        diff_string = [a_word]\n",
    "    elif opt_user == 'c':\n",
    "        print(\"ignore\")\n",
    "        diff_string = [a_word]\n",
    "    return diff_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd395e9f",
   "metadata": {},
   "source": [
    "### Get data and saved lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0f10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def revTrainTestData(pdf_data_search_dir, in_name):\n",
    "    data_mentions, dm_headers = csvh.get_csv_data(Path(pdf_data_search_dir, in_name+'.csv'))    \n",
    "    return data_mentions, dm_headers\n",
    "\n",
    "def save_list (a_list, name):\n",
    "    with open(name, \"w\") as f:\n",
    "        for s in a_list:\n",
    "            try: \n",
    "                f.write(str(s) +\"\\n\")\n",
    "            except: \n",
    "                print(\" could not write\", s )\n",
    "\n",
    "def get_list(name):\n",
    "    a_list = []\n",
    "    with open(name, \"r\") as f:\n",
    "        for line in f:\n",
    "            a_list.append(line.strip())\n",
    "    return a_list\n",
    "\n",
    "# Correct the description sentence\n",
    "#  get the sentences\n",
    "#  check if they are in the dictionary or on the non_dict words\n",
    "#    - if OK add to the return sentence list\n",
    "#    - else check the difficult work to see if it needs correcting\n",
    "#        add whathever is returned to the sentece list\n",
    "#  join the words in the list to form the corrected sentence\n",
    "def correct_desc(a_sentence, used_words=[], non_dict=[]):\n",
    "    eng_dict = enchant.Dict(\"en\")\n",
    "    return_sentence = []\n",
    "    items = a_sentence.split()\n",
    "    for itm_idx in items: \n",
    "        check_word = get_alphanum(itm_idx)\n",
    "        if check_word != \"\" and (eng_dict.check (check_word) or check_non_dict(check_word, non_dict)):\n",
    "            return_sentence.append(check_word)\n",
    "            used_words = add_word_to_list(used_words, check_word)\n",
    "        else: \n",
    "            diff_list = check_difficult(itm_idx, non_dict, used_words)\n",
    "            for aw in diff_list:\n",
    "                return_sentence.append(aw)\n",
    "                used_words.append(aw)\n",
    "    return \" \".join(return_sentence), used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7d8fb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original acquired concurrently with the copper reference foil placed between It and Iref XASdata processing, and EXAFS analysis were performed using IFEFFIT18 with theHorae package19 (Athena and Artemis).\n",
      "Corrected acquired concurrently with the copper reference foil placed between It and Iref XAS data processing and EXAFS analysis were performed using IFEFFIT 1 8 with the Horae package 1 9 Athena and Artemis\n",
      "continue?\n",
      "n\n",
      " could not write ï¬nalizing\n",
      " could not write ï¬ndingsof\n"
     ]
    }
   ],
   "source": [
    "# get train and test data\n",
    "\n",
    "# working directory\n",
    "pdf_data_search_dir = \"./data_search_pdf_b\"\n",
    "\n",
    "# file containing train and test data\n",
    "train_test_file =  'test_train01_rev'\n",
    "# non dictionary words\n",
    "non_dict_file = \"non_dict_list.txt\"\n",
    "# used_word file\n",
    "used_dict_file = \"used_dict_list.txt\"\n",
    "# results file\n",
    "out_test_file =  'test_train01_rev'\n",
    "\n",
    "data, headers = revTrainTestData(pdf_data_search_dir, train_test_file)\n",
    "uw=get_list(Path(pdf_data_search_dir, used_dict_file))\n",
    "nd= get_list(Path(pdf_data_search_dir, non_dict_file))\n",
    "\n",
    "#print(data)\n",
    "for item in data:\n",
    "    if(data[item][\"corrected\"] == \"\"):\n",
    "        entry_string = data[item][\"desc\"]\n",
    "        print(\"Original\", data[item][\"desc\"])\n",
    "        result_string , uw = correct_desc(data[item][\"desc\"],uw,nd)\n",
    "        clear_output()\n",
    "        data[item][\"corrected\"] = result_string\n",
    "        print(\"Original\", data[item][\"desc\"])\n",
    "        print(\"Corrected\", result_string )\n",
    "        print(\"continue?\")\n",
    "        opt_user = input()\n",
    "        if opt_user.lower() == \"n\":\n",
    "            save_list(nd, Path(pdf_data_search_dir, non_dict_file))\n",
    "            csvh.write_csv_data(data, Path(pdf_data_search_dir,  out_test_file +'.csv'))\n",
    "            if len(uw) > 0:\n",
    "                uw = set(uw)\n",
    "                uw = list(uw)\n",
    "                uw.sort()\n",
    "                save_list(uw, Path(pdf_data_search_dir, used_dict_file))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2c8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "            save_list(nd, Path(pdf_data_search_dir, non_dict_file))\n",
    "            csvh.write_csv_data(data, Path(pdf_data_search_dir,  out_test_file +'.csv'))\n",
    "            if len(uw) > 0:\n",
    "                uw = set(uw)\n",
    "                uw = list(uw)\n",
    "                uw.sort()\n",
    "                save_list(uw, Path(pdf_data_search_dir, used_dict_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b1d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
