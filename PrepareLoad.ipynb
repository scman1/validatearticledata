{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loading of data objects to App DB\n",
    "\n",
    "A curated list of data objects referenced from a set of publications is formated to facilitate loading into the App DB.\n",
    "\n",
    "Instead of only referencing to data, these process refer to **data objects**, which are any data which is published to complement the publication, this includes raw data, supplementary data, processing data, tables, images, movies, and compilations containing one or more of such resources (corrections to publications may fall in this category but need to discuss it with stakeholders).\n",
    "\n",
    "The operations to be performed are: \n",
    "- get metadata from objects identifed with DOIs and arrange it in a way that it can be loaded to the AppDB.\n",
    "- format all objects without DOI (mostly supplementary materials) to align with the metadata from DOI identified objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library containign read and write functions to csv file\n",
    "import lib.handle_csv as csvh\n",
    "\n",
    "# managing files and file paths\n",
    "from pathlib import Path\n",
    "\n",
    "# library for handling url searchs\n",
    "import lib.handle_urls as urlh\n",
    "\n",
    "# add a progress bar\n",
    "from tqdm import tqdm_notebook\n",
    "    \n",
    "# library for accessing system functions\n",
    "import os\n",
    "\n",
    "# import custom functions (common to various notebooks)\n",
    "import processing_functions as pr_fns\n",
    "\n",
    "# Connecting to the db\n",
    "import lib.handle_db as dbh\n",
    "\n",
    "# get the publications list from the app database\n",
    "ukchapp_db = \"../app_db.sqlite3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DOI objects metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names and links for references in data mentions\n",
    "data_reference, _ = csvh.get_csv_data('../pub_data_load.csv', 'num')\n",
    "\n",
    "# ast needed to parse string saved dictionary\n",
    "import ast\n",
    "\n",
    "for dr in tqdm_notebook(data_reference):\n",
    "    # get metadata if it is missing\n",
    "    if data_reference[dr]['do_metadata'] == \"\" and data_reference[dr]['do_doi'] != \"\":\n",
    "        ref_link = \"https://doi.org/\" + data_reference[dr]['do_doi']\n",
    "        data_object = urlh.getObjectMetadata(ref_link)\n",
    "        data_reference[dr]['do_metadata'] = data_object['metadata']\n",
    "    if data_reference[dr]['do_metadata'] != \"\":\n",
    "        do_metadata = ast.literal_eval(str(data_reference[dr]['do_metadata']))\n",
    "        data_reference[dr]['do_title'] = do_metadata['title']\n",
    "        print('Title: ', do_metadata['title'])\n",
    "        if 'abstract' in do_metadata:\n",
    "            print('Abstract: ', do_metadata['abstract'])\n",
    "            data_reference[dr]['do_description'] = do_metadata['abstract']\n",
    "        print('URL: ', do_metadata['URL'])\n",
    "        data_reference[dr]['do_location'] = do_metadata['URL']\n",
    "        print('DOI: ', do_metadata['DOI'])\n",
    "        data_reference[dr]['do_doi'] = do_metadata['DOI']\n",
    "        repo_address = urlh.getBaseUrl(do_metadata['URL'])\n",
    "        print('repository:', repo_address)\n",
    "        data_reference[dr]['do_repository'] = repo_address\n",
    "        print('Type:',do_metadata['type']) \n",
    "        data_reference[dr]['do_type'] = do_metadata['type']\n",
    "        if do_metadata['type'] != 'dataset':\n",
    "            data_reference[dr]['do_inferred_type'] = 'dataset'\n",
    "# write to csv file\n",
    "if len(data_reference) > 0:\n",
    "    csvh.write_csv_data(data_reference, '../pub_data_load.csv')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata to file objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names and links for references in data mentions\n",
    "data_reference, _ = csvh.get_csv_data('../pub_data_load.csv', 'num')\n",
    "\n",
    "db_conn = dbh.DataBaseAdapter(ukchapp_db)\n",
    "\n",
    "for dr in tqdm_notebook(data_reference):\n",
    "    \n",
    "    # get publication metadata to fill in missing fields in DO metadata\n",
    "    ref_link = \"https://doi.org/\" + data_reference[dr]['article_doi']\n",
    "    publication_title = db_conn.get_title(data_reference[dr]['article_doi'])\n",
    "    if data_reference[dr]['do_doi'] == \"\":\n",
    "        if data_reference[dr]['do_file']!=\"\":\n",
    "            do_title = data_reference[dr]['do_file'].split(\"/\")[1]\n",
    "            print(\"Title: \", do_title)\n",
    "            data_reference[dr]['do_title'] = do_title\n",
    "            print(\"Description: Supplementary information for \", publication_title)\n",
    "            data_reference[dr]['do_description'] = \"Supplementary data for \" + publication_title[0]\n",
    "            repo_address = urlh.getBaseUrl(data_reference[dr]['do_location'])\n",
    "            print('URL:', data_reference[dr]['do_location'])\n",
    "            print('Repository:', repo_address)\n",
    "            data_reference[dr]['do_repository'] = repo_address\n",
    "            do_type = data_reference[dr]['do_file'][data_reference[dr]['do_file'].rfind(\".\")+1:]\n",
    "            print(\"Type: \", do_type)\n",
    "            data_reference[dr]['do_type'] = do_type\n",
    "            \n",
    "# write to csv file\n",
    "if len(data_reference) > 0:\n",
    "    csvh.write_csv_data(data_reference, '..pub_data_load.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert into datasets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names and links for references in data mentions\n",
    "data_reference, _ = csvh.get_csv_data('pub_data_load.csv', 'num')\n",
    "\n",
    "db_conn = dbh.DataBaseAdapter(ukchapp_db)\n",
    "\n",
    "db_table = \"datasets\"\n",
    "table_columns = [\"dataset_complete\", \"dataset_description\",\"dataset_doi\",\"dataset_enddate\", \"dataset_location\",\n",
    "                  \"dataset_name\",\"dataset_startdate\",\"created_at\",\"updated_at\", \"ds_type\", \"repository\"]\n",
    "for dr in tqdm_notebook(data_reference):\n",
    "    if data_reference[dr]['do_location']!= \"\":\n",
    "        if data_reference[dr]['do_inferred_type'] != \"\":\n",
    "            do_type = data_reference[dr]['do_inferred_type']\n",
    "        else:\n",
    "            do_type = data_reference[dr]['do_type']\n",
    "        table_values = [None, data_reference[dr]['do_description'], data_reference[dr]['do_doi'], None, data_reference[dr]['do_location'],data_reference[dr]['do_title'], None,\n",
    "                        \"2020-11-25\", \"2020-11-25\" , do_type, data_reference[dr]['do_repository']]\n",
    "        db_conn.put_values_table(db_table, table_columns, table_values)\n",
    "        #get the id of inserted record\n",
    "        new_do_id = db_conn.get_value( db_table, \"id\", \"dataset_location\", data_reference[dr]['do_location'])[0]\n",
    "        print(new_do_id)\n",
    "        linktable = \"article_datasets\"\n",
    "        linktable_columns = [\"doi\", \"article_id\", \"dataset_id\", \"created_at\", \"updated_at\"]\n",
    "        linktable_values = [data_reference[dr]['article_doi'], data_reference[dr]['article_id'], new_do_id, \"2020-11-25\", \"2020-11-25\"]\n",
    "        db_conn.put_values_table(linktable, linktable_columns, linktable_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
