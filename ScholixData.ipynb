{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732dd680",
   "metadata": {},
   "source": [
    "# Look up in the scholix registry\n",
    "\n",
    "Read DOIs from rails app. Look up each DOI in the Scholix registry and save links to a csv file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a167a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library containign read and write functions to csv file\n",
    "import lib.handle_csv as csvh\n",
    "\n",
    "# library for handling url searchs\n",
    "import lib.handle_urls as urlh\n",
    "\n",
    "# library for connecting to the db\n",
    "import lib.handle_db as dbh\n",
    "\n",
    "# import custom functions (common to various notebooks)\n",
    "import processing_functions as pr_fns\n",
    "\n",
    "# managing files and file paths\n",
    "from pathlib import Path\n",
    "\n",
    "# add aprogress bar\n",
    "from tqdm import tqdm_notebook \n",
    "from tqdm import tqdm\n",
    "\n",
    "# regular expressions\n",
    "import re\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3756ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of already searched DOIs\n",
    "doi_list = ['10.1002/chem.202000067', '10.1016/j.jcat.2018.01.033', '10.1021/acscatal.9b03889', \n",
    "            '10.1039/d0cp01227k', '10.1039/d0cy01061h', '10.1098/rsta.2020.0058', '10.1098/rsta.2020.0063', \n",
    "            '10.1039/D0CY01608J', '10.1021/acs.est.0c04279', '10.1039/D0CP01192D', '10.1039/d0cy01779e', \n",
    "            '10.1021/acsenergylett.0c02614', '10.1039/d1fd00004g', '10.3390/catal10121370', \n",
    "            '10.1039/d1gc00901j', '10.1038/s41467-021-21062-1', '10.1021/acscatal.0c05413',\n",
    "            '10.1021/acscatal.0c04858', '10.1088/1361-648x/abfe16', '10.1088/1361-6463/abe9e1', \n",
    "            '10.1039/d0sc03113e', '10.1007/s11244-021-01447-8', '10.1021/acs.organomet.1c00055', \n",
    "            '10.1021/acscatal.0c05019', '10.1021/acs.inorgchem.1c00327', '10.1002/smsc.202100032', \n",
    "            '10.1039/d0gc02295k', '10.1002/anie.201901592', '10.1021/acs.organomet.9b00845', \n",
    "            '10.1021/jacs.9b13106', '10.1002/anie.202006807', '10.1021/jacs.0c07980', '10.1039/d0cy01484b',\n",
    "            '10.1039/d0cy02164d', '10.1002/anie.202101180', '10.1002/chem.202101140', \n",
    "            '10.1021/acsmacrolett.1c00216', '10.1002/anie.201810245', '10.1039/c9sc00385a', \n",
    "            '10.1021/acs.macromol.8b01224', '10.1039/c9dt02918d', '10.1038/s41467-019-10481-w', \n",
    "            '10.1002/ange.201901592', '10.1039/c9dt00595a', '10.1039/d1cy00238d', \n",
    "            '10.1021/acs.inorgchem.8b02923', '10.1002/ange.202006807', '10.1002/anie.201814320', \n",
    "            '10.1007/s10562-019-02876-7', '10.1021/acs.jpcc.9b09050', '10.1016/j.apcatb.2017.01.042',\n",
    "            '10.1039/d0cc04036c', '10.1002/anie.202015016', '10.1039/d1ta01464a', '10.1002/smtd.202100512',\n",
    "            '10.1107/s1600576720013576', '10.1039/d0cp00793e', '10.1039/d0ta01398f', \n",
    "            '10.1007/s11244-021-01450-z', '10.1039/d0ta08351h', '10.1021/acssuschemeng.1c01451',\n",
    "            '10.1002/cphc.201800721', '10.1021/acssuschemeng.8b04073', '10.1002/cctc.202100286', \n",
    "            '10.1007/s11244-020-01245-8', '10.1021/acscatal.0c03620', '10.1016/j.cattod.2018.06.033', \n",
    "            '10.1016/j.apcatb.2020.118752', '10.1016/j.joule.2020.07.024', '10.1002/anie.201814381', \n",
    "            '10.1002/ange.201902857']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1c6a6",
   "metadata": {},
   "source": [
    "## Search for references direclty in scholexplorer\n",
    "The next code makes a search of scholix references to data using the scholexeplorer of OpenAire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e62aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up in sholix\n",
    "# Get pdf and html name from previous and put it in current\n",
    "def search_scolix(db_name):\n",
    "    out_name = \"search_scholix_\"+db_name\n",
    "    out_file = Path(out_name + \".csv\")\n",
    "    if out_file.is_file():\n",
    "        print (\"Already searched for\", db_name)\n",
    "        return out_name\n",
    "    data_links = {}\n",
    "    a_dl = {}\n",
    "    url_base = 'http://api.scholexplorer.openaire.eu/v2/Links?sourcePid='\n",
    "    ignore_types = ['References','IsReferencedBy']\n",
    "\n",
    "    terminate = False\n",
    "\n",
    "    for a_pub in tqdm_notebook(app_pubs):\n",
    "        pub_id = a_pub[0]\n",
    "        pub_title = a_pub[1]\n",
    "        pub_doi = a_pub[2]\n",
    "        pub_url = a_pub[3]\n",
    "        match_found = False\n",
    "        if pr_fns.valid_doi(pub_doi) and pub_id > 0:\n",
    "            response = urlh.getPageFromURL(url_base + pub_doi.replace('/','%2f'))\n",
    "            data_results = json.loads(response)\n",
    "            id_dl = len(data_links)\n",
    "            for a_result in data_results['result']:\n",
    "                if not a_result['RelationshipType']['Name'] in ignore_types:\n",
    "                    id_dl += 1\n",
    "                    source_doi = pub_doi\n",
    "                    source_title = a_result['source']['Title'].replace('\\n',' ')\n",
    "                    source_published = a_result['source']['PublicationDate']\n",
    "                    target_id = a_result['target']['Identifier'][0]['ID']\n",
    "                    target_type = a_result['target']['Type']\n",
    "                    if not pr_fns.valid_doi(target_id) and target_type != 'literature':\n",
    "                        if a_result['target']['Identifier'][0]['IDScheme'] in ['uniprot','pdb']:\n",
    "                            target_id = a_result['target']['Identifier'][0]['IDURL']\n",
    "                        else:\n",
    "                            for an_id in a_result['target']['Identifier']:\n",
    "                                print (\"source\", source_doi, \"title\", source_title)\n",
    "                                print (an_id)\n",
    "                            terminate = True    \n",
    "                    target_title = a_result['target']['Title'].replace('\\n',' ')\n",
    "                    target_published = a_result['target']['PublicationDate']\n",
    "\n",
    "                    rel_type = a_result['RelationshipType']['Name']\n",
    "\n",
    "                    a_dl = {\"pub_id\": pub_id,\"pub_doi\":source_doi,'source_title':source_title, 'source_published':source_published,\n",
    "                            'target_id':target_id, 'target_title':target_title, \n",
    "                            'target_published': target_published, 'rel_type': rel_type}\n",
    "                    data_links[id_dl]=a_dl\n",
    "        if terminate:\n",
    "            break\n",
    "    print ('References found:', len(data_links))\n",
    "\n",
    "    \n",
    "    if len(data_links) > 0  and not terminate:\n",
    "        csvh.write_csv_data(data_links, out_name + \".csv\")\n",
    "    return out_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15460c",
   "metadata": {},
   "source": [
    "## Remove duplicates\n",
    "search for potential duplicates in list (hapens when same target with different relationship tipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4d9d4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# search for potential duplicates in list (hapens when same target with different relationship tipes)\n",
    "def remove_dups(srf_name):\n",
    "    out_name = srf_name + \"_no_dups\"\n",
    "    out_file = Path(out_name + \".csv\")\n",
    "    if out_file.is_file():\n",
    "        print (\"already removed duplicates from:\", srf_name)\n",
    "        return out_name\n",
    "    data_links = {}\n",
    "    a_dl = {}\n",
    "    scholix_references, column_names = csvh.get_csv_data(srf_name+\".csv\")\n",
    "\n",
    "    scholix_look_up, look_up_names = csvh.get_csv_data(srf_name+\".csv\")\n",
    "\n",
    "    for a_ref in tqdm_notebook(scholix_references):\n",
    "        for look_up in scholix_look_up:\n",
    "            if scholix_look_up[look_up] != scholix_references[a_ref] \\\n",
    "               and not 'duplicate' in scholix_references[a_ref].keys():\n",
    "                if scholix_look_up[look_up]['pub_doi'] == scholix_references[a_ref]['pub_doi'] \\\n",
    "                   and scholix_look_up[look_up]['target_id'] == scholix_references[a_ref]['target_id'] \\\n",
    "                   and scholix_look_up[look_up]['target_title'] == scholix_references[a_ref]['target_title']:\n",
    "                    scholix_references[look_up]['duplicate'] = 'TRUE'\n",
    "                    print (a_ref ,scholix_references[a_ref])\n",
    "                    print (look_up, scholix_look_up[look_up])\n",
    "        if not 'duplicate' in scholix_references[a_ref].keys():\n",
    "            scholix_references[a_ref]['duplicate'] = 'FALSE'\n",
    "            with open(out_name + \".csv\", 'a', newline='',encoding='utf8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(scholix_references[a_ref].values())\n",
    "    return out_name\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17236d",
   "metadata": {},
   "source": [
    "## Check if pdf mentions are on DB\n",
    "Merge results with those of references mined from publications in preparation for fairnes validation before upload to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6961b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look if already referenced in DB\n",
    "\n",
    "def check_if_in_db(ndf_name, srf_name):\n",
    "    out_name = srf_name + \"_not_in_DB\"\n",
    "    out_file = Path(out_name + \".csv\")\n",
    "    if out_file.is_file():\n",
    "        print (\"Already checked DB for:\", ndf_name)\n",
    "        return out_name\n",
    "\n",
    "    # get list of references with no duplicates\n",
    "\n",
    "    scholix_references, column_names = csvh.get_csv_data(ndf_name + \".csv\")\n",
    "    int_counter = 0\n",
    "    unique_refs = {}\n",
    "\n",
    "    pub_id = ''\n",
    "    for a_ref in tqdm_notebook(scholix_references):\n",
    "        pub_id = scholix_references[a_ref]['pub_id']\n",
    "        ref_id = scholix_references[a_ref]['target_id']\n",
    "        ref_title = scholix_references[a_ref]['target_title']\n",
    "        pub_datsets = pr_fns.get_pub_datasets(ukchapp_db, pub_id)\n",
    "        int_counter += 1\n",
    "        #print(int_counter, scholix_references[a_ref], pub_datsets)\n",
    "        print(f'***************PUBLICATION %s******************'%pub_id)\n",
    "        identifier_found = False\n",
    "        for a_ds in pub_datsets:\n",
    "            ds_id = a_ds[0]\n",
    "            ds_doi = a_ds[1]\n",
    "            ds_url = a_ds[2]\n",
    "            ds_name = a_ds[3]\n",
    "            if ds_doi != None and ds_doi.strip().lower() == ref_id.strip().lower():\n",
    "                #print (\"DOI FOUND\")\n",
    "                identifier_found = True\n",
    "            elif ds_url.strip().lower() == ref_id.strip().lower():\n",
    "                #print (\"URL FOUND\")\n",
    "                identifier_found = True\n",
    "            elif '?' in ds_url and not pr_fns.valid_doi(ref_id):\n",
    "                print(\"URL with extra parameters\",ds_url)\n",
    "                print (\"compared to\", ref_id)\n",
    "            if identifier_found == True:\n",
    "                scholix_references[a_ref]['in_db'] = 1\n",
    "                if ds_name == ref_title:\n",
    "                    #print('DS Name Match')\n",
    "                    scholix_references[a_ref]['title_match'] = 1\n",
    "                #else:\n",
    "                    #print('DS Name Different')\n",
    "                break\n",
    "            else:\n",
    "                scholix_references[a_ref]['in_db'] = 0\n",
    "\n",
    "    if len(scholix_references) > 0:\n",
    "        csvh.write_csv_data(scholix_references, out_name + \".csv\")\n",
    "    return out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93de626",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get names and links for references in data mentions\n",
    "def check_pdf_data(db_name):\n",
    "    in_name = 'pdf_mentions'+db_name+'_valid'\n",
    "    in_file = Path(in_name + \".csv\")\n",
    "    if not in_file.is_file():\n",
    "        print (\"In file not found:\", in_name , \"pdf_mentionsapp_db202204_valid\")\n",
    "        return \"\"\n",
    "    out_name = 'pdf_mentions'+db_name+'_checked'\n",
    "    out_file = Path(out_name + \".csv\")\n",
    "    if out_file.is_file():\n",
    "        print (\"Already checked DB for:\", in_name)\n",
    "        return out_name\n",
    "\n",
    "\n",
    "    data_mentions, dm_fields = csvh.get_csv_data('pdf_mentionsapp_db202204_valid.csv', 'num')\n",
    "    int_counter = 0\n",
    "    for dm in data_mentions:\n",
    "        pub_id = data_mentions[dm]['id']\n",
    "        pub_doi = data_mentions[dm]['doi']\n",
    "        ref_name = data_mentions[dm]['name']\n",
    "        ref_link = data_mentions[dm]['data_url']\n",
    "        ref_id =  data_mentions[dm]['do_id']\n",
    "        #print (ref_name, ref_link, ref_id)\n",
    "        pub_datsets = pr_fns.get_pub_datasets(ukchapp_db, pub_id)\n",
    "        int_counter += 1\n",
    "        #print(int_counter, scholix_references[a_ref], pub_datsets)\n",
    "        print(f'***************PUBLICATION %s******************'%pub_id)\n",
    "        identifier_found = False\n",
    "        if data_mentions[dm]['add'] == '1':\n",
    "            for a_ds in pub_datsets:\n",
    "                ds_id = a_ds[0]\n",
    "                ds_doi = a_ds[1]\n",
    "                ds_url = a_ds[2]\n",
    "                ds_name = a_ds[3]\n",
    "                if ds_doi != None and ds_doi.strip().lower() == ref_id.strip().lower():\n",
    "                    #print (\"DOI FOUND\")\n",
    "                    identifier_found = True\n",
    "                elif ds_url.strip().lower() == ref_id.strip().lower():\n",
    "                    #print (\"URL FOUND\")\n",
    "                    identifier_found = True\n",
    "                elif '?' in ds_url and not pr_fns.valid_doi(ref_id):\n",
    "                    print(\"URL with extra parameters\",ds_url)\n",
    "                    print (\"compared to\", ref_id)\n",
    "                if identifier_found == True:\n",
    "                    data_mentions[dm]['in_db'] = 1\n",
    "                    if ds_name == ref_title:\n",
    "                        #print('DS Name Match')\n",
    "                        data_mentions[dm]['title_match'] = 1\n",
    "                    #else:\n",
    "                        #print('DS Name Different')\n",
    "                    break\n",
    "\n",
    "    if len(data_mentions) > 0:\n",
    "        csvh.write_csv_data(data_mentions, out_name +\".csv\")\n",
    "    return out_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ff99d",
   "metadata": {},
   "source": [
    "## Merge db filtered PDF results and Scholix results\n",
    "Merge results with those of references mined from publications in preparation for fairnes validation before upload to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "749568f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_results (scholix_results, pdf_results, db_name):\n",
    "    scholix_file = Path(scholix_results + \".csv\")\n",
    "    pdfresu_file = Path(pdf_results + \".csv\")    \n",
    "    \n",
    "    # if the required files do not exist\n",
    "    if (not scholix_file.is_file()) and (not pdfresu_file.is_file()):\n",
    "        print (\"In file not found:\", in_name)\n",
    "        return \"\"\n",
    "    out_name = 'new_references_'+db_name\n",
    "    out_file = Path(out_name + \".csv\")\n",
    "    if out_file.is_file():\n",
    "        print (\"Already created merge DB for:\", scholix_results, pdf_results)\n",
    "        return out_name\n",
    "\n",
    "    # get names and links for references in db checked data mentions\n",
    "    data_mentions, dm_fields = csvh.get_csv_data('pdf_mentionsapp_db202204_checked.csv', 'num')\n",
    "    # get list of references with no duplicates\n",
    "    scholix_references, column_names = csvh.get_csv_data(\"search_scholix_app_db202204_valid.csv\")\n",
    "\n",
    "    merged_references ={}\n",
    "    # first just copy all the references in scholix to the merged set\n",
    "    print(\"Copy all the references in scholix to the merged set\")\n",
    "    for a_ref in tqdm_notebook(scholix_references):\n",
    "        if scholix_references[a_ref]['in_db']!= '1':\n",
    "            merged_references[a_ref] = scholix_references[a_ref]\n",
    "\n",
    "    print (\"Check if the data mention is in the scholix references\")\n",
    "    new_idx = len(scholix_references) # start adding after the highest index for scholix\n",
    "    ccdc_count = len(scholix_references)\n",
    "    found_count = 0\n",
    "    for dm in tqdm_notebook(data_mentions):\n",
    "        pub_id = data_mentions[dm]['id']\n",
    "        pub_doi = data_mentions[dm]['doi']\n",
    "        ref_name = data_mentions[dm]['dataset_name']\n",
    "        ref_link = data_mentions[dm]['data_url']\n",
    "        ref_id =  data_mentions[dm]['do_id']\n",
    "        ref_rel = data_mentions[dm]['type']\n",
    "        print (pub_id,pub_doi,\"REF \",ref_name,ref_link,ref_id,ref_rel)\n",
    "        found_match = False\n",
    "        if data_mentions[dm]['add'] == '1' and data_mentions[dm]['in_db'] != '1' :\n",
    "            for a_ref in merged_references:\n",
    "                if ccdc_count < a_ref:\n",
    "                    break\n",
    "                mr_pub_id = merged_references[a_ref]['pub_id']\n",
    "                mr_pub_doi = merged_references[a_ref]['pub_doi']\n",
    "                mr_id = merged_references[a_ref]['target_id']\n",
    "                mr_title = merged_references[a_ref]['target_title']\n",
    "                # pub_id, pub_doi, and ref_id must match if the reference is already found in scholix\n",
    "                if pub_doi.strip().lower() == mr_pub_doi.strip().lower() and \\\n",
    "                    pub_id == mr_pub_id and \\\n",
    "                    ref_id.strip().lower() == mr_id.strip().lower():\n",
    "                    found_count += 1\n",
    "                    print(\"found match\", found_count, dm, a_ref)\n",
    "                    found_match = True\n",
    "                    merged_references[a_ref]['in_pdf']=1\n",
    "                    print (pub_doi.strip().lower(), mr_pub_doi.strip().lower(), pub_id, mr_pub_id,\n",
    "                           ref_id, mr_id)\n",
    "                    break\n",
    "            if not found_match:\n",
    "                new_idx += 1 \n",
    "                a_dl = {\"pub_id\": pub_id,\"pub_doi\":pub_doi,'source_title':'', \n",
    "                        'source_published':'',\n",
    "                        'target_id':ref_id, \n",
    "                        'target_title':ref_name, \n",
    "                        'target_published': '', \n",
    "                        'rel_type': ref_rel,\n",
    "                        'in_pdf':1}\n",
    "                if not pr_fns.valid_doi(ref_id):\n",
    "                    #print(ref_id, ref_link)\n",
    "                    a_dl['target_id'] = ref_link\n",
    "                merged_references[new_idx] = a_dl\n",
    "\n",
    "    if len(merged_references) > 0:\n",
    "        csvh.write_csv_data(merged_references, out_name+\".csv\")\n",
    "        print (len(merged_references), \"merged references\")\n",
    "    return out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3201f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already searched for app_db202204\n",
      "1. Shcolix results stored in: search_scholix_app_db202204.csv\n",
      "already removed duplicates from: search_scholix_app_db202204\n",
      "2. Non duplicate shcolix results stored in: search_scholix_app_db202204_no_dups.csv\n",
      "Already checked DB for: search_scholix_app_db202204_no_dups\n",
      "3. Non in DB shcolix results stored in: search_scholix_app_db202204_not_in_DB.csv\n",
      "Already checked DB for: pdf_mentionsapp_db202204_valid\n",
      "4. Non in DB pdf results stored in: pdf_mentionsapp_db202204_checked.csv\n",
      "Already created merge DB for: search_scholix_app_db202204_not_in_DB pdf_mentionsapp_db202204_checked\n",
      "5. all data mentions stored in: new_references_app_db202204.csv\n"
     ]
    }
   ],
   "source": [
    "# Set the name of currend app DB\n",
    "db_name = 'app_db202204'\n",
    "ukchapp_db = \"db_files/\"+db_name+\".sqlite3\"\n",
    "while not Path(ukchapp_db).is_file():\n",
    "    print('Please enter the name of app db file:')\n",
    "    ukchapp_db = input()\n",
    "\n",
    "# Get publication data from the ukch app\n",
    "app_pubs = pr_fns.get_pub_app_data(ukchapp_db)\n",
    "\n",
    "schlx_search_result = search_scolix(db_name)\n",
    "print (\"1. Shcolix results stored in:\", schlx_search_result+\".csv\") \n",
    "schlx_search_nd = remove_dups(schlx_search_result)\n",
    "print (\"2. Non duplicate shcolix results stored in:\", schlx_search_nd+\".csv\") \n",
    "schlx_search_ndb = check_if_in_db(schlx_search_nd, schlx_search_result)\n",
    "print (\"3. Non in DB shcolix results stored in:\", schlx_search_ndb+\".csv\")\n",
    "pdfsrc_db = check_pdf_data(db_name)\n",
    "print (\"4. Non in DB pdf results stored in:\", pdfsrc_db+\".csv\")\n",
    "merged_res = merge_results(schlx_search_ndb, pdfsrc_db, db_name)\n",
    "print (\"5. all data mentions stored in:\", merged_res +\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e2cc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_references_app_db202204'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f862e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
