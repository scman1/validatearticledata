{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of references to UK Catalysis Hub \n",
    "A list of articles is obtainded from publish or perish. This list will contain a titles and some IDs whic need to be verified. \n",
    "\n",
    "The criteria for adding a publication to the database are: \n",
    "a) has an explicit acknowledgement of UK Catalysis Hub\n",
    "b) mentions one of the UK Catalysis Hub grants\n",
    "c) has two or more authors with affiliation to UK Catalysis Hub\n",
    "d) acknowledges support from a scientist affiliated to UK Catalysis Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# library containign functions that read and write to csv files\n",
    "import lib.handle_csv as csvh\n",
    "# library for connecting to the db\n",
    "import lib.handle_db as dbh\n",
    "# library for handling text matchings\n",
    "import lib.text_comp as txtc\n",
    "# library for getting data from crossref\n",
    "import lib.crossref_api as cr_api\n",
    "# library for handling url searchs\n",
    "import lib.handle_urls as urlh\n",
    "# managing files and file paths\n",
    "from pathlib import Path\n",
    "# add aprogress bar\n",
    "from tqdm import tqdm_notebook \n",
    "# library for getting data from crossref\n",
    "import lib.crossref_api as cr_api\n",
    "#library for handling json files\n",
    "import json\n",
    "# library for using regular expressions\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the crossreference json page from doi\n",
    "def get_cr_json_object(cr_doi):\n",
    "  crjd = None\n",
    "  doi_file = 'json_files/' + cr_doi.replace('/','_').lower() + '.json'\n",
    "  if not Path(doi_file).is_file():\n",
    "    crjd = cr_api.getBibData(cr_doi)\n",
    "    with open(doi_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(crjd, f, ensure_ascii=False, indent=4)\n",
    "  else:\n",
    "    jf = open(doi_file, 'r')\n",
    "    crjd = json.load(jf)\n",
    "  # return the content and the file name \n",
    "  return crjd, doi_file\n",
    "\n",
    "# get the landing page for the publication from uri\n",
    "\n",
    "                    \n",
    "def get_titles(str_pub_title, db_name = \"prev_search.sqlite3\"):\n",
    "    print(db_name)\n",
    "    db_conn = dbh.DataBaseAdapter(db_name)\n",
    "    search_in = 'prev_pop_searches'\n",
    "    fields_required = \"Num, Title\"\n",
    "    filter_str = \"Title like '\"+str_pub_title[0]+\"%';\"\n",
    "\n",
    "    db_titles = db_conn.get_values(search_in, fields_required, filter_str)\n",
    "    db_conn.close()\n",
    "    return db_titles\n",
    "\n",
    "def get_titles_and_dois(str_pub_title, db_name = \"app_db.sqlite3\"):\n",
    "    print(db_name)\n",
    "    db_conn = dbh.DataBaseAdapter(db_name)\n",
    "    search_in = 'articles'\n",
    "    fields_required = \"id, title, doi\"\n",
    "    filter_str = \"Title like '\"+str_pub_title[0]+\"%';\"\n",
    "\n",
    "    db_titles = db_conn.get_values(search_in, fields_required, filter_str)\n",
    "    db_conn.close()\n",
    "    return db_titles\n",
    "\n",
    "# get the current csv working file\n",
    "def get_working_file(nr_wf):\n",
    "    working_file = wf_fields = None\n",
    "    current_pass = 0\n",
    "    if Path(nr_wf).is_file():\n",
    "        working_file, wf_fields = csvh.get_csv_data(nr_wf,'Num')\n",
    "        for art_num in tqdm_notebook(working_file):\n",
    "            if current_pass < int(working_file[art_num]['ignore']):\n",
    "                current_pass = int(working_file[art_num]['ignore'])\n",
    "    print(\"Current pass:\", current_pass)\n",
    "    return working_file, wf_fields, current_pass\n",
    "\n",
    "def get_pub_html_doi(cr_doi):\n",
    "    html_file = 'html_files/' + cr_doi.replace('/','_').lower() + '.html'\n",
    "    if not Path(html_file).is_file():\n",
    "        page_content = urlh.getPageFromDOI(doi_text)\n",
    "        with open(html_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(page_content.decode(\"utf-8\") )\n",
    "    else:\n",
    "        f = open(html_file, \"r\")\n",
    "        page_content = f.read()\n",
    "    return page_content, html_file\n",
    "\n",
    "def get_pub_html_url(text_url, entry_id):\n",
    "    html_file = 'html_files/' +  entry_id + '.html'\n",
    "    if not Path(html_file).is_file():\n",
    "        print(\"\")\n",
    "        page_content = urlh.getPageFromURL(text_url)\n",
    "        with open(html_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(page_content)\n",
    "    else:\n",
    "        f = open(html_file, \"r\")\n",
    "        page_content = f.read()\n",
    "    return page_content, html_file\n",
    "\n",
    "def valid_doi(cr_doi):\n",
    "    # CR DOIS: https://www.crossref.org/blog/dois-and-matching-regular-expressions/\n",
    "    # CR DOIs re1\n",
    "    # /^10.\\d{4,9}/[-._;()/:A-Z0-9]+$/i\n",
    "    cr_re_01 = '^10.\\d{4,9}/[-._;()/:A-Z0-9]+'\n",
    "    compare = re.match(cr_re_01, cr_doi, re.IGNORECASE)\n",
    "    if compare != None and cr_doi == compare.group():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d389d29ea314c53bfadb31e913e5e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current pass: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69437271662d42b397481deb15f0d12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doi.org/10.1177/1468087420962294\n",
      "Title:  A comparative study into the effects of pre and post catalyst exhaust gas recirculation on the onset of knock\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1038/s41467-020-17852-8\n",
      "Title:  Adsorption and activation of molecular oxygen over atomic copper (I/II) site on ceria\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "The project is funded by EPSRC (EP/P02467X/1 and EP/S018204/1), Royal Society (RG160661 and IES\\R3\\170097), the Newton International Fellowship (NF170761). We acknowledge Diamond Light Source beamtime (EM17559, SP17377, SP24285, NT15763, EM19318 and EM19246) and the UK Catalysis Hub block allocation for beamtime (SP15151 and SP19850). We acknowledge Helmholz-Zentrum Berlin for the beamtime in BESSY II (18207435-ST and 19108389-ST). We acknowledge SPring-8 for the operando XAFS experiments conducted under the proposal no. 2019A1533. The UK Catalysis Hub is kindly thanked for resources and support provided via our membership of the UK Catalysis Hub Consortium and funded by EPSRC (grants EP/ K014706/2, EP/K014668/1, EP/K014854/1, EP/K014714/1 and EP/M013219/1). This research has been performed with the use of facilities at the Research Complex at Harwell including MP-AES equipment. The authors would like to thank the Research Complex for access and support to these facilities and equipment. XPS data collection were performed at the EPSRC National Facility for XPS (‘HarwellXPS’), operated by Cardiff University and UCL, under contract No.\n",
      "Title:  Adsorption and activation of molecular oxygen over atomic copper (I/II) site on ceria\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "The project is funded by EPSRC (EP/P02467X/1 and EP/S018204/1), Royal Society (RG160661 and IES\\R3\\170097), the Newton International Fellowship (NF170761). We acknowledge Diamond Light Source beamtime (EM17559, SP17377, SP24285, NT15763, EM19318 and EM19246) and the UK Catalysis Hub block allocation for beamtime (SP15151 and SP19850). We acknowledge Helmholz-Zentrum Berlin for the beamtime in BESSY II (18207435-ST and 19108389-ST). We acknowledge SPring-8 for the operando XAFS experiments conducted under the proposal no. 2019A1533. The UK Catalysis Hub is kindly thanked for resources and support provided via our membership of the UK Catalysis Hub Consortium and funded by EPSRC (grants EP/ K014706/2, EP/K014668/1, EP/K014854/1, EP/K014714/1 and EP/M013219/1). This research has been performed with the use of facilities at the Research Complex at Harwell including MP-AES equipment. The authors would like to thank the Research Complex for access and support to these facilities and equipment. XPS data collection were performed at the EPSRC National Facility for XPS (‘HarwellXPS’), operated by Cardiff University and UCL, under contract No.\n",
      "https://doi.org/10.1039/d0cp03852k\n",
      "Title:  An approach to calculate the free energy changes of surface reactions using free energy decomposition on ab initio brute-force molecular dynamics …\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.respol.2020.104045\n",
      "Title:  Anchor entrepreneurship and industry catalysis: The rise of the Italian Biomedical Valley\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1039/c8fd90016g\n",
      "Title:  Application of new nanoparticle structures as catalysts: general discussion\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "c\n",
      "going to next\n",
      "https://doi.org/10.1021/acscatal.7b02733\n",
      "Title:  Atmospheric Pressure and Room Temperature Synthesis of Methanol through Plasma-Catalytic Hydrogenation of CO2\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acsami.7b15456\n",
      "Title:  Biocatalytic self-assembly on magnetic nanoparticles\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1039/d0sc01918f\n",
      "Title:  Catalyst control of selectivity in the C–O bond alumination of biomass derived furans\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1515/chem-2018-0055\n",
      "Title:  Catalytic activities of heterogeneous catalysts obtained by copolymerization of metal-containing 2-(acetoacetoxy) ethyl methacrylate\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1142/9789813237179_0010\n",
      "Title:  CHALLENGES FOR ORGANOCATALYSIS\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "c\n",
      "going to next\n",
      "https://doi.org/10.1021/acs.jpcc.8b08461\n",
      "Title:  CO and O2 Adsorption on K/Pt(111)\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1039/d0cy01061h\n",
      "Title:  Cobalt-containing zeolitic imidazole frameworks for C–H activation using visible-light redox photocatalysis\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "The work was funded by the EU's Horizon 2020 program under grant number 720783 (MULTI2HYCAT) and EPSRC (UK) (EP/N013883/1). CPR was funded through a joint University of Southampton and A*STAR, Singapore scholarship. The beamtime was carried out at B18, Diamond Light Source under proposal SP-15151 via the UK Catalysis Hub Beamtime Allocation Group. \n",
      "https://doi.org/10.1016/j.trechm.2020.03.002\n",
      "Title:  Cofactor NAD (P) H Regeneration: How Selective Are the Reactions?\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "c\n",
      "going to next\n",
      "thesis is not a valid DOI\n",
      "10.1039/c8cy90033g  is not a valid DOI\n",
      "https://doi.org/10.5286/edata/736\n",
      "Title:  Dataset for the publication:\" The methyl torsion in unsaturated compounds\" published in ACS Omega (2019) by Zachariou et al.\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "c\n",
      "going to next\n",
      "https://doi.org/10.1038/s41929-018-0169-3\n",
      "Title:  Detection of catalytic intermediates at an electrode surface during carbon dioxide reduction by an earth-abundant catalyst\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.mcat.2018.06.002\n",
      "Title:  Effect of the addition of different doping agents on visible light activity of porous TiO2 photocatalysts\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1038/s41598-017-19135-7\n",
      "Title:  Effects of distal mutations on the structure, dynamics and catalysis of human monoacylglycerol lipase\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.jcat.2018.01.033\n",
      "Title:  Effects of zeolite particle size and internal grain boundaries on Pt/Beta catalyzed isomerization of n-pentane\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Enter ack text: \n",
      "This work was supported by the National Natural Science Foundation of China (21706067 and 91434117), the China Postdoctoral Science Foundation (2016M600289) and the Fundamental Research Funds for the Central Universities (222201714004 and 222201718003). M.-O.C is supported by the EPSRC “Frontier Engineering” Centre for Nature Inspired Engineering (EP/K038656/1) and the UK Catalysis Hub (EP/K014706/1).\n",
      "https://doi.org/10.1016/j.elecom.2017.12.017\n",
      "Title:  Electrocatalytic activity of CoFe2O4 thin films prepared by AACVD towards the oxygen evolution reaction in alkaline media\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.apsusc.2017.11.076\n",
      "Title:  Electrocatalytic behavior of a nanocomposite of Ni/Pd supported by carbonized PVA nanofibers towards formic acid, ethanol and urea oxidation: a physicochemical …\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acs.cgd.7b01552\n",
      "Title:  Formation and Elimination of Anti-site Defects during Crystallization in Perovskite Ba1–xSrxLiF3\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/jacs.0c04747\n",
      "Title:  Hydration of a 2D Supramolecular Assembly: Bitartrate on Cu (110)\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1039/c8se00338f\n",
      "Title:  Hydrogen production from formic acid decomposition in the liquid phase using Pd nanoparticles supported on CNFs with different surface properties\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acs.organomet.8b00377\n",
      "Title:  Hydrogenation of Carbon Dioxide with Organic Base by PCIIP-Ir Catalysts\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "thesis is not a valid DOI\n",
      "https://doi.org/10.1016/j.cattod.2020.07.003\n",
      "Title:  Iron porphyrin-derived ordered carbonaceous frameworks\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acs.jpclett.8b01888\n",
      "Title:  Lonely atoms with special gifts: Breaking linear scaling relationships in heterogeneous catalysis with single-atom alloys\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acscatal.0c01454\n",
      "Title:  Mechanistic Insight into the Framework Methylation of H-ZSM-5 for Varying Methanol Loadings and Si/Al Ratios Using First-Principles Molecular Dynamics …\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.3390/chemistry2030048\n",
      "Title:  Membrane-Supported Recovery of Homogeneous Organocatalysts: A Review\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "thesis is not a valid DOI\n",
      "https://doi.org/10.1016/j.apcata.2018.04.006\n",
      "Title:  MFI zeolite coating with intrazeolitic aluminum (acidic) gradient supported on SiC foams to improve the methanol-to-propylene (MTP) reaction\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "dataset is not a valid DOI\n",
      "https://doi.org/10.1002/solr.202000281\n",
      "Title:  Molecular Cobalt Catalysts Grafted onto Polymers for Efficient Hydrogen Generation Cathodes\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1002/adsc.202001047\n",
      "Title:  N–N Bond Formation using an Iodonitrene as an Umpolung of Ammonia: Straightforward and Chemoselective Synthesis of Hydrazinium Salts\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.mtener.2018.02.007\n",
      "Title:  Ni and Cu ion-exchanged nanostructured mesoporous zeolite: A noble metal free, efficient, and durable electrocatalyst for alkaline methanol oxidation reaction\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1098/rsta.2020.0063\n",
      "Title:  Octane isomer dynamics in H-ZSM-5 as a function of Si/Al ratio: a quasi-elastic neutron scattering study\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "We acknowledge the Engineering and Physical Sciences Research Council (EPSRC): grant no. EP/G036675/1 for financial support under their Centres for Doctoral Training scheme and the Science and Technologies Facilities Council. The UK Catalysis Hub is kindly thanked for resources and support provided via our membership of the UK Catalysis Hub Consortium and funded by EPSRC (grant nos EP/K014706/1, EP/K014668/1, EP/K014854/1EP/K014714/1 and EP/M013219/1). The data upon which this paper is based may be accessed from the ISIS Data Catalogue (https://data.isis.stfc.ac.uk/) using the RB numbers specified above.\n",
      "https://doi.org/10.1098/rsta.2020.0063\n",
      "Title:  Octane isomer dynamics in H-ZSM-5 as a function of Si/Al ratio: a quasi-elastic neutron scattering study\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "We acknowledge the Engineering and Physical Sciences Research Council (EPSRC): grant no. EP/G036675/1 for financial support under their Centres for Doctoral Training scheme and the Science and Technologies Facilities Council. The UK Catalysis Hub is kindly thanked for resources and support provided via our membership of the UK Catalysis Hub Consortium and funded by EPSRC (grant nos EP/K014706/1, EP/K014668/1, EP/K014854/1EP/K014714/1 and EP/M013219/1). The data upon which this paper is based may be accessed from the ISIS Data Catalogue (https://data.isis.stfc.ac.uk/) using the RB numbers specified above.\n",
      "https://doi.org/10.1002/chem.201804515\n",
      "Title:  Palladium‐Catalyzed C(sp3)−H Arylation of Primary Amines Using a Catalytic Alkyl Acetal to Form a Transient Directing Group\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acscentsci.7b00607\n",
      "Title:  Pendant Hydrogen-Bond Donors in Cobalt Catalysts Independently Enhance CO2 Reduction\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.scitotenv.2020.141154\n",
      "Title:  Photocatalytic removal of the cyanobacterium Microcystis aeruginosa PCC7813 and four microcystins by TiO2 coated porous glass beads with UV-LED irradiation\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.3390/catal8120578\n",
      "Title:  Policies and motivations for the CO2 valorization through the sabatier reaction using structured catalysts. A review of the most recent advances\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.jcat.2020.06.021\n",
      "Title:  Probing the electronic and geometric structures of photoactive electrodeposited Cu2O films by X-ray absorption spectroscopy\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Enter ack text: \n",
      "We thank University College London (UCL) and the Agency for Science, Technology and Research (A*STAR), Singapore, Research Attachment Programme (ARAP) for financial support for MY.  We thank Dr Hayama for helping with the I20 beamline set up and Diamond Light Source for providing beam time and other facilities, Ms Tahmin Lais, Department of Chemistry, UCL, for assistance with XAS data collection, and Dr Stephen Price at the UK Catalysis Hub, Harwell, for taking the side on SEM images of all films. ADH acknowledges partial support from A*STAR through The Accelerated Catalyst Development Platform (SC25/19-8R1228).\n",
      "https://doi.org/10.1021/acsami.8b08674\n",
      "Title:  Protecting Ceria Nanocatalysts—The Role of Sacrificial Barriers\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1073/pnas.1805046115\n",
      "Title:  Protein kinase Cα gain-of-function variant in Alzheimer's disease displays enhanced catalysis by a mechanism that evades down-regulation\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acs.jpclett.0c02885\n",
      "Title:  Protonation-Induced Dynamic Allostery in PDZ Domain: Evidence of Perturbation-Independent Universal Response Network\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1039/c8nr02237b\n",
      "Title:  Re-evaluating how charge transfer modifies the conformation of adsorbed molecules\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.cattod.2020.05.045\n",
      "Title:  Real-time tomographic diffraction imaging of catalytic membrane reactors for the oxidative coupling of methane\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "The authors would also like to thank Wilm Jones and Donato Decarolis for help with acquisition of the XAFS BCFZ data and the UK Catalysis Hub and the Diamond Light Source for the bag time at beamline B18. \n",
      "https://doi.org/10.1021/acs.jcim.8b00165\n",
      "Title:  Redesigning the materials and catalysts database construction process using ontologies\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.resenv.2020.100003\n",
      "Title:  Selection of Manganese oxide catalysts for catalytic oxidation of Carbon monoxide at ambient conditions\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1021/acs.chemmater.8b01672.s001\n",
      "Title:  Strain engineering and Raman spectroscopy of monolayer transition metal dichalcogenides\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1002/aic.17007\n",
      "Title:  Structured Ni@ NaA zeolite supported on silicon carbide foam catalysts for catalytic carbon dioxide methanation\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "This project has received funding from European Union's Horizon 2020 research and innovation programme under grant agreement No.872102. HC thanks the financial support from the European Commission Marie Skłodowska‐Curie Individual Fellowship (H2020‐MSCA‐IF‐NTPleasure‐748196). UK Catalysis Hub is kindly thanked for resources and support provided via our membership of the UK Catalysis Hub Consortium and funded by EPRSC grant: EP/R026939/1, EP/R026815/1, EP/R026645/1, and EP/R027129/1.\n",
      "https://doi.org/10.1021/acssuschemeng.8b03268\n",
      "Title:  Sulfated Zirconia Catalysts for D-Sorbitol Cascade Cyclodehydration to Isosorbide: Impact of Zirconia Phase\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "X.Z., K.W., and A.F.L. thank the UK Catalysis Hub and EPSRC for the award for funding under (EP/K014706 and EP/K036548/2). K.W. acknowledges the Royal Society for the award of an Industry Fellowship, and A.F.L. thanks the EPSRC for the award of a Leadership Fellowship (EP/G007594/2). MEL Chemicals is gratefully acknowledged for their supply of zirconia supports.\n",
      "https://doi.org/10.1080/08940886.2018.1460180\n",
      "Title:  Synchrotron Radiation and Neutrons for Catalysis, Materials Research and Development\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.poly.2018.08.027\n",
      "Title:  Synthesis and characterization of AgCoO2 catalyst for oxidation of CO at a low temperature\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.21820/23987073.2018.9.65\n",
      "Title:  The Cardiff Catalysis Institute: A Premium Research Institute\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.cattod.2020.09.001\n",
      "Title:  The direct synthesis of hydrogen peroxide over Au and Pd nanoparticles: A DFT study\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1038/s41929-018-0176-4\n",
      "Title:  The role of computational results databases in accelerating the discovery of catalysts\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.21820/23987073.2018.5.16\n",
      "Title:  Towards a deeper understanding of catalytic activity in supported precious metal catalysts, EPSRC\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1016/j.apcatb.2020.119256\n",
      "Title:  Understanding structure-activity relationships in highly active La promoted Ni catalysts for CO2 methanation\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "a\n",
      "Enter ack text: \n",
      "E.R.A. and E.R.C. thank to thank to project RTI2018-099668-BC22 of Ministerio de Ciencia, Innovación y Universidades and project UMA18-FEDERJA-126 of Junta de Andalucía and FEDER funds. W. Jones and D. Decarolis acknowledge Innovate UK (104253) & EPSRC (EP/R026815/1) respectively. We also acknowledge XAFS measurements performed through the UK Catalysis Hub BAG access.\n",
      "https://doi.org/10.1080/02772248.2018.1497634\n",
      "Title:  Visible light sensitive activated carbon-metal oxide (TiO2, WO3, NiO, and SnO) nano-catalysts for photo-degradation of methylene blue: a comparative study\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "https://doi.org/10.1039/c8ta08015a\n",
      "Title:  Water oxidation catalysed by quantum-sized BiVO 4\n",
      "***************************************************************\n",
      "Options:\n",
      "\ta) add ack text\n",
      "\tb) mark as not relevant\n",
      "\tc) go to next\n",
      "selection:\n",
      "b\n",
      "going to next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nr_wf = \"pop_searches/PoPCites20201017_wf.csv\"\n",
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "if current_pass >= 6:\n",
    "    i = 0\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0' and working_file[art_num]['ack_fragment'] == \"\":\n",
    "            article_id = working_file[art_num]['Num']\n",
    "            article_title = working_file[art_num]['Title']\n",
    "            article_doi = working_file[art_num]['DOIcr']\n",
    "            request_str = \"https://doi.org/\" + article_doi \n",
    "            if valid_doi(article_doi):\n",
    "                request_str = \"https://doi.org/\" + article_doi \n",
    "                print(request_str)\n",
    "                \n",
    "                #display(HTML('<h1>Hello, world!</h1>'))\n",
    "                #%%html\n",
    "                #<iframe src=request_str  width=\"600\" height=\"400\"></iframe>\n",
    "                IFrame(request_str, width=700, height=350)\n",
    "                inspected = False\n",
    "                while not inspected:\n",
    "                    #new_title = working_file[art_num]['Title']\n",
    "                    print('Title: ', article_title)\n",
    "                    print('***************************************************************')\n",
    "                    print(\"Options:\\n\\ta) add ack text\\n\\tb) mark as not relevant\\n\\tc) go to next\")\n",
    "                    print(\"selection:\")\n",
    "                    usr_select = input()\n",
    "                    if usr_select == 'c':\n",
    "                        #working_file[art_num]['ignore']=3 # visual inspection\n",
    "                        inspected = True\n",
    "                        working_file[art_num]['send_to_corinne'] = 'no'\n",
    "                        working_file[art_num]['reason_send'] = \"not acknowledged, no UKCH authors\"\n",
    "                        print(\"going to next\")\n",
    "                    elif usr_select == 'b':\n",
    "                        #working_file[art_num]['ignore']=3 # visual inspection\n",
    "                        inspected = True\n",
    "                        print(\"going to next\")\n",
    "                    elif usr_select == 'a':\n",
    "                        inspected = True\n",
    "                        ack_text = \"\"\n",
    "                        while ack_text == \"\":\n",
    "                            print(\"Enter ack text: \")\n",
    "                            ack_text = input()\n",
    "                            working_file[art_num]['ack_fragment'] = ack_text\n",
    "                            working_file[art_num]['send_to_corinne'] = 'yes'\n",
    "                            working_file[art_num]['reason_send'] = \"confirmed in acknowledgements\"\n",
    "            else:\n",
    "                print(article_doi, \"is not a valid DOI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop_searches/PoPCites20201017_wf.csv\n"
     ]
    }
   ],
   "source": [
    "csvh.write_csv_data(working_file, nr_wf)  \n",
    "print(nr_wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the name of the file with the results of the PoP search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file with path: pop_searches/PoPCites20201017.csv\n",
    "new_results_file = \"\"\n",
    "while not Path(new_results_file).is_file():\n",
    "    print('Please enter the name of the input file:')\n",
    "    new_results_file = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the name of the db file with previous results of the PoP search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous results db file with path: db_files/prev_search.sqlite3\n",
    "\n",
    "previous_db = \"\"\n",
    "while not Path(previous_db).is_file():\n",
    "    print('Please enter the name of the previous results file:')\n",
    "    previous_db = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the name of the current app db file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app db file with path: db_files/app_db.sqlite3\n",
    "ukchapp_db = \"\"\n",
    "while not Path(ukchapp_db).is_file():\n",
    "    print('Please enter the name of the previous results file:')\n",
    "    ukchapp_db = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the name of the output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_wf = new_results_file[:-4]+\"_wf.csv\"\n",
    "print(\"Verifying if the articles listed in: \\n\\t\", Path(new_results_file).name)\n",
    "print(\"where included in previous searches: \\n\\t\", Path(previous_db).name)\n",
    "\n",
    "print(\"The results will bt saved in: \\n\\t\", nr_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the working file before each step\n",
    "working_file = wf_fields = None\n",
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify if already processed titles are included\n",
    "Read data and verify if results in file have already been included in previous searches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "if current_pass == 0:\n",
    "    current_initial = \"\"\n",
    "    db_titles = []\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        new_title = working_file[art_num]['Title'].lower()\n",
    "        working_file[art_num]['ignore'] = 0 \n",
    "        working_file[art_num]['previous'] = 0 \n",
    "        working_file[art_num]['similarity'] = 0.0\n",
    "        if current_initial == \"\" or current_initial != new_title[0]:\n",
    "            print(\"new intital \", new_title[0])\n",
    "            current_initial = new_title[0]\n",
    "            db_titles = get_titles(current_initial, previous_db)\n",
    "            \n",
    "        for prev_pair in db_titles:\n",
    "            prev_num = prev_pair[0]\n",
    "            used_title = prev_pair[1].lower()\n",
    "            # if titles match exactly or simialarity > 0.8 ignore\n",
    "            title_similarity = txtc.similar(new_title, used_title)\n",
    "            if title_similarity > 0.80:\n",
    "                #print(art_num, 'Title:', new_title, \"already processed\", prev_num, used_title)\n",
    "                working_file[art_num]['ignore'] = 1\n",
    "                working_file[art_num]['previous'] = prev_num\n",
    "                working_file[art_num]['similarity'] = title_similarity\n",
    "                break\n",
    "\n",
    "    csvh.write_csv_data(working_file, nr_wf)  \n",
    "    print(nr_wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Titles in app\n",
    "Verify if the title is in the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "# verify that titles are not in the app_db (if they are  also get DOI)\n",
    "if current_pass == 1: \n",
    "    db_titles = []\n",
    "    current_initial = \"\"\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            new_title = working_file[art_num]['Title'].lower()\n",
    "            if current_initial == \"\" or current_initial != new_title[0]:\n",
    "                print(\"new intital \", new_title[0])\n",
    "                current_initial = new_title[0]\n",
    "                db_titles = get_titles_and_dois(current_initial, ukchapp_db)\n",
    "            for art_in_db in db_titles:\n",
    "                prev_num = art_in_db[0]\n",
    "                used_title = art_in_db[1].lower()\n",
    "                # if titles match exactly or simialarity > 0.8 ignore\n",
    "                title_similarity = txtc.similar(new_title, used_title)\n",
    "                if title_similarity > 0.80:\n",
    "                    #print(art_num, 'Title:', new_title, \"already processed\", prev_num, used_title)\n",
    "                    working_file[art_num]['ignore'] = 2\n",
    "                    working_file[art_num]['previous'] = prev_num\n",
    "                    working_file[art_num]['similarity'] = title_similarity\n",
    "                    working_file[art_num]['DOIcr'] = art_in_db[2]\n",
    "                    break                \n",
    "    csvh.write_csv_data(working_file, nr_wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Title Wording\n",
    "Using the workds in previous catalysis hub papers check if the title is likely to be a cat hub title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "if current_pass < 3:\n",
    "    # pass 2\n",
    "    # check titles for likelihood of being catalysis articles using keywords from titles in current DB \n",
    "    print(\"Get word list from DB\")\n",
    "    x = dbh.DataBaseAdapter(ukchapp_db)\n",
    "    db_titles = x.get_value_list('articles','title')\n",
    "    title_words = set()\n",
    "    ignore_words=set(['the','of','to','and','a','in','is','it', 'their', 'so', 'as'])\n",
    "    average = 0\n",
    "    words_sum = 0.0\n",
    "    for title in db_titles:\n",
    "        one_title = set(title.lower().split())\n",
    "        one_title = one_title - ignore_words\n",
    "        title_words = title_words.union(one_title)\n",
    "        words_sum += len(one_title) \n",
    "        \n",
    "    average = words_sum /len(db_titles)\n",
    "    print(\"Average words per title:\", average)\n",
    "    title_words = title_words - ignore_words\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if 0 == int(working_file[art_num]['ignore']):\n",
    "            art_title = working_file[art_num]['Title']\n",
    "            art_words = set(art_title.lower().split())\n",
    "            occurrences = len(title_words.intersection(art_words))\n",
    "            working_file[art_num]['keywords']=occurrences\n",
    "            if occurrences == 0:\n",
    "                print(\"occurrences:\", occurrences, \"in title:\", art_title)\n",
    "                working_file[art_num]['ignore']=3\n",
    "            else:\n",
    "                print(\"occurrences:\", occurrences, \"in title:\", art_title)\n",
    "    csvh.write_csv_data(working_file, nr_wf)\n",
    "    x.close()\n",
    "    current_pass = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "if current_pass == 3:\n",
    "    i = 0\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            inspected = False\n",
    "            while not inspected:\n",
    "                new_title = working_file[art_num]['Title']\n",
    "                keywords = working_file[art_num]['keywords']\n",
    "                #print (keywords, new_title)\n",
    "                if keywords < 3 and not (\"cataly\" in new_title.lower()):\n",
    "                # ignore  it because it does not contains cataly in title\n",
    "                    working_file[art_num]['ignore']=4 # visual inspection\n",
    "                    inspected = True\n",
    "                else:\n",
    "                    inspected = True\n",
    "    print(\"To Process:\", i, \"Pass:\", current_pass)\n",
    "    csvh.write_csv_data(working_file, nr_wf)\n",
    "    current_pass = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DOIs for Articles\n",
    "The remaining titles need to be further analysed. Recovering their DOIs helps to obtain abstracts and acknowledgement statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "if current_pass == 4:\n",
    "    i = 0\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0' and working_file[art_num]['DOIcr']==\"\":\n",
    "            new_title = working_file[art_num]['Title']\n",
    "            new_doi = cr_api.getDOIForTitle(new_title)\n",
    "            if new_doi == \"\":\n",
    "                #print(\"Missing DOI:\", new_title)\n",
    "                working_file[art_num]['ignore'] = '5'\n",
    "                i +=1\n",
    "            else:\n",
    "                #print(\"DOI found:\", new_doi, \"for:\", new_title)\n",
    "                working_file[art_num]['DOIcr'] = new_doi\n",
    "                working_file[art_num]['ignore'] = '0'\n",
    "    print(\"without DOI:\", i)\n",
    "    csvh.write_csv_data(working_file, nr_wf)\n",
    "    current_pass = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify DOIs in DB\n",
    "Verify that articles do not exist in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "\n",
    "if current_pass == 5:\n",
    "    i = 0\n",
    "    db_conn = dbh.DataBaseAdapter(ukchapp_db)\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            new_title = working_file[art_num]['Title']\n",
    "            new_doi = working_file[art_num]['DOIcr'].strip()\n",
    "            db_title = db_conn.get_title(new_doi)\n",
    "            if db_title == None:\n",
    "                print(\"Not in DB:\", new_doi, new_title)\n",
    "            else:\n",
    "                print(\"Already in DB:\", new_doi, \"for:\", new_title, db_title)\n",
    "                working_file[art_num]['ignore'] = '6'\n",
    "    print(\"without DOI:\", i)\n",
    "    csvh.write_csv_data(working_file, nr_wf)\n",
    "    current_pass = 6\n",
    "    dbh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get full json files for remaining articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "\n",
    "if current_pass >= 6:\n",
    "    i = 0\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            article_title = working_file[art_num]['Title']\n",
    "            article_doi = working_file[art_num]['DOIcr']\n",
    "            article_url =working_file[art_num]['ArticleURL']\n",
    "            data, file_name = get_cr_json_object(article_doi)\n",
    "            if data != {}:\n",
    "                working_file[art_num]['file'] = file_name\n",
    "    csvh.write_csv_data(working_file, nr_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "\n",
    "if current_pass >= 6:\n",
    "    i = 1\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            article_title = working_file[art_num]['Title']\n",
    "            article_doi = working_file[art_num]['DOIcr']\n",
    "            article_url =working_file[art_num]['ArticleURL']\n",
    "            data, file_name = get_cr_json_object(article_doi)\n",
    "            print(i, article_title, article_doi)\n",
    "            #print(data.keys())\n",
    "            epsrc_keys = ['EP/R026645/1', 'EP/K014668/1', 'EP/K014714/1', 'EP/R026815/1', 'EP/R026939/1',\n",
    "                          'EP/M013219/1', 'EP/R027129/1', 'EP/K014854/1', 'EP/K014706/2']\n",
    "            confirmed_in_cr = []\n",
    "            if 'funder' in data.keys():\n",
    "                for a_funder in data['funder']:\n",
    "                    for an_award in a_funder['award']:\n",
    "                        if an_award in epsrc_keys:\n",
    "                            print(\"Found\", an_award)\n",
    "                            confirmed_in_cr.append(an_award)\n",
    "                working_file[art_num]['award_in_cr'] = ', '.join(confirmed_in_cr)\n",
    "            i += 1\n",
    "    csvh.write_csv_data(working_file, nr_wf)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get full HTML files for remaining articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_wf = \"pop_searches/PoPCites20201017_wf.csv\"\n",
    "working_file, wf_fields, current_pass = get_working_file(nr_wf)\n",
    "\n",
    "if current_pass >= 6:\n",
    "    i = 0\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            article_id = working_file[art_num]['Num']\n",
    "            article_title = working_file[art_num]['Title']\n",
    "            article_doi = working_file[art_num]['DOIcr'].strip().lower()\n",
    "            article_url =working_file[art_num]['ArticleURL']\n",
    "            article_type =working_file[art_num]['type']\n",
    "            html_content = file_name = None\n",
    "            if valid_doi(article_doi):\n",
    "                html_content, file_name = get_pub_html_doi(article_doi)\n",
    "            else:\n",
    "                #try with url\n",
    "                html_content = None\n",
    "                #identifier = \"id\" + str((1000000 + int(article_id)))[1,6] + article_type \n",
    "                #html_content, file_name = get_pub_html_doi(article_url, identifier)\n",
    "            if html_content != None:\n",
    "                working_file[art_num]['html_file'] = file_name\n",
    "                \n",
    "    csvh.write_csv_data(working_file, nr_wf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#***************************************************************************************************************\n",
    "# Wait do not run this yet\n",
    "#***************************************************************************************************************\n",
    "if current_pass >= 6:\n",
    "    i = 0\n",
    "    for art_num in tqdm_notebook(working_file):\n",
    "        if working_file[art_num]['ignore']=='0':\n",
    "            article_title = working_file[art_num]['Title']\n",
    "            article_doi = working_file[art_num]['DOIcr']\n",
    "            article_url =working_file[art_num]['ArticleURL']\n",
    "            print(\"Analysing:\", article_title, article_doi, article_url)\n",
    "            # try to retrive html page for article using link from crossref first\n",
    "            # and if not try url from pop\n",
    "            # find reference to uk catalysis hub in html text\n",
    "            # if found mark as relevant\n",
    "            found = \"\"\n",
    "            referents = [\"uk catalysis hub\", \"uk catalysis\", \"catalysis hub\",\n",
    "                 'EP/R026645/1', 'resources', 'EP/K014668/1', 'EPSRC', 'EP/K014714/1',\n",
    "                 'Hub','provided', 'grant', 'biocatalysis', 'EP/R026815/1', 'EP/R026939/1',\n",
    "                 'support', 'membership', 'EP/M013219/1', 'UK', 'kindly', 'Catalysis',\n",
    "                 'funded', 'EP/R027129/1', 'Consortium', 'thanked', 'EP/K014854/1', 'EP/K014706/2']\n",
    "            found = urlh.findFromDOI(article_title, article_doi, referents)\n",
    "            working_file[art_num]['checked_doi'] = 1\n",
    "            working_file[art_num]['ack_doi'] = found\n",
    "            found = urlh.findFromURI(article_title, article_url, referents)\n",
    "            working_file[art_num]['checked_url'] = 1\n",
    "            working_file[art_num]['ack_url'] = found\n",
    "            print(\"Ack:\", found)\n",
    "    csvh.write_csv_data(working_file, nr_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_text = '10.1039/d0cy00036a'\n",
    "\n",
    "url_text = \"https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.808495\"\n",
    "\n",
    "html_content, file_name = get_pub_html_doi(doi_text)\n",
    "\n",
    "print(file_name)#, html_content)\n",
    "\n",
    "import re\n",
    "\n",
    "#print(len(doi_text))\n",
    "# CR DOIS: https://www.crossref.org/blog/dois-and-matching-regular-expressions/\n",
    "# CR DOIs re1\n",
    "# /^10.\\d{4,9}/[-._;()/:A-Z0-9]+$/i\n",
    "\n",
    "cr_re_01 = '^10.\\d{4,9}/[-._;()/:A-Z0-9]+'\n",
    "\n",
    "compare = re.match(cr_re_01, doi_text, re.IGNORECASE)\n",
    "\n",
    "print(compare)\n",
    "print(compare.start())\n",
    "print(compare.end())\n",
    "print(compare.group())\n",
    "\n",
    "if compare != None and doi_text == compare.group():\n",
    "    print(\"This is a DOI: \", doi_text)\n",
    "else:\n",
    "    print(\"This is not a DOI: \", doi_text)\n",
    "\n",
    "compare = re.match(cr_re_01, url_text, re.IGNORECASE)\n",
    "    \n",
    "print(url_text, valid_doi(url_text))\n",
    "print(doi_text, valid_doi(doi_text))\n",
    "\n",
    "# url_text = \"https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.808495\"\n",
    "# id = id000069_thesis\n",
    "entry_id = 'id000069_thesis'\n",
    "\n",
    "html_content, file_name = get_pub_html_url(url_text, entry_id)\n",
    "print(file_name, html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_text = '10.1039/d0cy00036a'\n",
    "print(doi_text, valid_doi(doi_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsrc_keys = ['EP/R026645/1', 'EP/K014668/1', 'EP/K014714/1', 'EP/R026815/1', 'EP/R026939/1',\n",
    "                          'EP/M013219/1', 'EP/R027129/1', 'EP/K014854/1', 'EP/K014706/2']\n",
    "', '.join(epsrc_keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
